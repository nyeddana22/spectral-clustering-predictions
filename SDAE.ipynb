{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EMYh7L3r1xRI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import numpy as np\n",
    "import gzip\n",
    "import torch\n",
    "import pickle\n",
    "import torch.utils.data as data\n",
    "import codecs\n",
    "import urllib\n",
    "class Netflix(data.Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train  # training set or test set\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.training_file = \"/Users/niharika/Documents/Niharika/Third Quarter/ECS 271 ML/Assignment2/user_pred_matrix.npy\" # your data for clustering (e.g., user-predictions matrix, user-embedding learned from SVD ...)\n",
    "        self.label_file = \"/Users/niharika/Documents/Niharika/Third Quarter/ECS 271 ML/Assignment2/labels.npy\" # clustering labels (not applicable for our assignment, I used the k-means labels for svd_pu file)\n",
    "        if download:\n",
    "            self.download()\n",
    "        train = np.load(self.training_file)\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        label = np.load(self.label_file)\n",
    "        train = scaler.fit_transform(train)\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.tensor(train, dtype=torch.float32), torch.tensor(label, dtype=torch.int)\n",
    "            if self.use_cuda:\n",
    "                self.train_data = self.train_data.cuda()\n",
    "                self.train_labels = self.train_labels.cuda()\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.tensor(train, dtype=torch.float32), torch.tensor(label, dtype=torch.int)\n",
    "            if self.use_cuda:\n",
    "                self.test_data = self.test_data.cuda()\n",
    "                self.test_labels = self.test_labels.cuda()\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fQT5YNTI2l5Q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        if torch.cuda.is_available():\n",
    "            self.data = self.data.cuda()\n",
    "            self.labels = self.labels.cuda()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], self.labels[index]\n",
    "        # img = Image.fromarray(img)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def masking_noise(data, frac):\n",
    "    \"\"\"\n",
    "    data: Tensor\n",
    "    frac: fraction of unit to be masked out\n",
    "    \"\"\"\n",
    "    data_noise = data.clone()\n",
    "    rand = torch.rand(data.size())\n",
    "    data_noise[rand<frac] = 0\n",
    "    return data_noise\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return 0.5 * torch.mean((input-target)**2)\n",
    "\n",
    "class BCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return -torch.mean(torch.sum(target*torch.log(torch.clamp(input, min=1e-10))+\n",
    "            (1-target)*torch.log(torch.clamp(1-input, min=1e-10)), 1))\n",
    "        \n",
    "\n",
    "def adjust_learning_rate(init_lr, optimizer, epoch):\n",
    "    lr = init_lr * (0.1 ** (epoch//100))\n",
    "    toprint = True\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group[\"lr\"]!=lr:\n",
    "            param_group[\"lr\"] = lr\n",
    "            if toprint:\n",
    "                print(\"Switching to learning rate %f\" % lr)\n",
    "                toprint = False\n",
    "\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activation=\"relu\", \n",
    "        dropout=0.2, tied=False):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if tied:\n",
    "            self.deweight = self.weight.t()\n",
    "        else:\n",
    "            self.deweight = Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.bias = Parameter(torch.Tensor(out_features))\n",
    "        self.vbias = Parameter(torch.Tensor(in_features))\n",
    "        \n",
    "        if activation==\"relu\":\n",
    "            self.enc_act_func = nn.ReLU()\n",
    "        elif activation==\"sigmoid\":\n",
    "            self.enc_act_func = nn.Sigmoid()\n",
    "        elif activation==\"none\":\n",
    "            self.enc_act_func = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 0.01\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "        stdv = 0.01\n",
    "        self.deweight.data.uniform_(-stdv, stdv)\n",
    "        self.vbias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.enc_act_func is not None:\n",
    "            return self.dropout(self.enc_act_func(F.linear(x, self.weight, self.bias)))\n",
    "        else:\n",
    "            return self.dropout(F.linear(x, self.weight, self.bias))\n",
    "\n",
    "    def encode(self, x, train=True):\n",
    "        if train:\n",
    "            self.dropout.train()\n",
    "        else:\n",
    "            self.dropout.eval()\n",
    "        if self.enc_act_func is not None:\n",
    "            return self.dropout(self.enc_act_func(F.linear(x, self.weight, self.bias)))\n",
    "        else:\n",
    "            return self.dropout(F.linear(x, self.weight, self.bias))\n",
    "\n",
    "    def encodeBatch(self, dataloader):\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        encoded = []\n",
    "        for batch_idx, (inputs, _) in enumerate(dataloader):\n",
    "            inputs = inputs.view(inputs.size(0), -1).float()\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            inputs = Variable(inputs)\n",
    "            hidden = self.encode(inputs, train=False)\n",
    "            encoded.append(hidden.data.cpu())\n",
    "\n",
    "        encoded = torch.cat(encoded, dim=0)\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, x, binary=False):\n",
    "        if not binary:\n",
    "            return F.linear(x, self.deweight, self.vbias)\n",
    "        else:\n",
    "            return F.sigmoid(F.linear(x, self.deweight, self.vbias))\n",
    "\n",
    "    def fit(self, trainloader, validloader, lr=0.001, batch_size=128, num_epochs=10, corrupt=0.3,\n",
    "        loss_type=\"mse\"):\n",
    "        \"\"\"\n",
    "        data_x: FloatTensor\n",
    "        valid_x: FloatTensor\n",
    "        \"\"\"\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        print(\"=====Denoising Autoencoding layer=======\")\n",
    "        # optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=lr)\n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, self.parameters()), lr=lr, momentum=0.9)\n",
    "        if loss_type==\"mse\":\n",
    "            criterion = MSELoss()\n",
    "        elif loss_type==\"cross-entropy\":\n",
    "            criterion = BCELoss()\n",
    "\n",
    "        # validate\n",
    "        total_loss = 0.0\n",
    "        total_num = 0\n",
    "        for batch_idx, (inputs, _) in enumerate(validloader):\n",
    "            # inputs = inputs.view(inputs.size(0), -1).float()\n",
    "            # if use_cuda:\n",
    "            #     inputs = inputs.cuda()\n",
    "            inputs = Variable(inputs)\n",
    "            hidden = self.encode(inputs)\n",
    "            if loss_type==\"cross-entropy\":\n",
    "                outputs = self.decode(hidden, binary=True)\n",
    "            else:\n",
    "                outputs = self.decode(hidden)\n",
    "\n",
    "            valid_recon_loss = criterion(outputs, inputs)\n",
    "            total_loss += valid_recon_loss.data * len(inputs)\n",
    "            total_num += inputs.size()[0]\n",
    "\n",
    "        valid_loss = total_loss / total_num\n",
    "        print(\"#Epoch 0: Valid Reconstruct Loss: %.4f\" % (valid_loss))\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            # train 1 epoch\n",
    "            train_loss = 0.0\n",
    "            adjust_learning_rate(lr, optimizer, epoch)\n",
    "            for batch_idx, (inputs, _) in enumerate(trainloader):\n",
    "                # inputs = inputs.view(inputs.size(0), -1).float()\n",
    "                inputs_corr = masking_noise(inputs, corrupt)\n",
    "                # if use_cuda:\n",
    "                #     inputs = inputs.cuda()\n",
    "                #     inputs_corr = inputs_corr.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                inputs = Variable(inputs)\n",
    "                inputs_corr = Variable(inputs_corr)\n",
    "\n",
    "                hidden = self.encode(inputs_corr)\n",
    "                if loss_type==\"cross-entropy\":\n",
    "                    outputs = self.decode(hidden, binary=True)\n",
    "                else:\n",
    "                    outputs = self.decode(hidden)\n",
    "                recon_loss = criterion(outputs, inputs)\n",
    "                train_loss += recon_loss.data*len(inputs)\n",
    "                recon_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # validate\n",
    "            valid_loss = 0.0\n",
    "            for batch_idx, (inputs, _) in enumerate(validloader):\n",
    "                # inputs = inputs.view(inputs.size(0), -1).float()\n",
    "                # if use_cuda:\n",
    "                #     inputs = inputs.cuda()\n",
    "                inputs = Variable(inputs)\n",
    "                hidden = self.encode(inputs, train=False)\n",
    "                if loss_type==\"cross-entropy\":\n",
    "                    outputs = self.decode(hidden, binary=True)\n",
    "                else:\n",
    "                    outputs = self.decode(hidden)\n",
    "\n",
    "                valid_recon_loss = criterion(outputs, inputs)\n",
    "                valid_loss += valid_recon_loss.data * len(inputs)\n",
    "\n",
    "            print(\"#Epoch %3d: Reconstruct Loss: %.4f, Valid Reconstruct Loss: %.4f\" % (\n",
    "                epoch+1, train_loss / len(trainloader.dataset), valid_loss / len(validloader.dataset)))\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1YJc7tnj1VzH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def buildNetwork(layers, activation=\"relu\", dropout=0):\n",
    "    net = []\n",
    "    for i in range(1, len(layers)):\n",
    "        net.append(nn.Linear(layers[i-1], layers[i]))\n",
    "        if activation==\"relu\":\n",
    "            net.append(nn.ReLU())\n",
    "        elif activation==\"sigmoid\":\n",
    "            net.append(nn.Sigmoid())\n",
    "        if dropout > 0:\n",
    "            net.append(nn.Dropout(dropout))\n",
    "    return nn.Sequential(*net)\n",
    "\n",
    "def adjust_learning_rate(init_lr, optimizer, epoch):\n",
    "    lr = init_lr * (0.1 ** (epoch//100))\n",
    "    toprint = True\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group[\"lr\"]!=lr:\n",
    "            param_group[\"lr\"] = lr\n",
    "            if toprint:\n",
    "                print(\"Switching to learning rate %f\" % lr)\n",
    "                toprint = False\n",
    "\n",
    "class StackedDAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, z_dim=10, binary=True,\n",
    "        encodeLayer=[400], decodeLayer=[400], activation=\"relu\", \n",
    "        dropout=0, tied=False):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.layers = [input_dim] + encodeLayer + [z_dim]\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.encoder = buildNetwork([input_dim] + encodeLayer, activation=activation, dropout=dropout)\n",
    "        self.decoder = buildNetwork([z_dim] + decodeLayer, activation=activation, dropout=dropout)\n",
    "        self._enc_mu = nn.Linear(encodeLayer[-1], z_dim)\n",
    "        \n",
    "        self._dec = nn.Linear(decodeLayer[-1], input_dim)\n",
    "        self._dec_act = None\n",
    "        if binary:\n",
    "            self._dec_act = nn.Sigmoid()\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder(z)\n",
    "        x = self._dec(h)\n",
    "        if self._dec_act is not None:\n",
    "            x = self._dec_act(x)\n",
    "        return x\n",
    "\n",
    "    def loss_function(self, recon_x, x):\n",
    "        loss = -torch.mean(torch.sum(x*torch.log(torch.clamp(recon_x, min=1e-10))+\n",
    "            (1-x)*torch.log(torch.clamp(1-recon_x, min=1e-10)), 1))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z = self._enc_mu(h)\n",
    "\n",
    "        return z, self.decode(z)\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        pretrained_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        model_dict.update(pretrained_dict) \n",
    "        self.load_state_dict(model_dict)\n",
    "\n",
    "    def pretrain(self, trainloader, validloader, lr=0.001, batch_size=128, num_epochs=10, corrupt=0.2, loss_type=\"cross-entropy\"):\n",
    "        trloader = trainloader\n",
    "        valoader = validloader\n",
    "        daeLayers = []\n",
    "        for l in range(1, len(self.layers)):\n",
    "            infeatures = self.layers[l-1]\n",
    "            outfeatures = self.layers[l]\n",
    "            if l!= len(self.layers)-1:\n",
    "                dae = DenoisingAutoencoder(infeatures, outfeatures, activation=self.activation, dropout=corrupt)\n",
    "            else:\n",
    "                dae = DenoisingAutoencoder(infeatures, outfeatures, activation=\"none\", dropout=0)\n",
    "            print(dae)\n",
    "            if l==1:\n",
    "                dae.fit(trloader, valoader, lr=lr, batch_size=batch_size, num_epochs=num_epochs, corrupt=corrupt, loss_type=loss_type)\n",
    "            else:\n",
    "                if self.activation==\"sigmoid\":\n",
    "                    dae.fit(trloader, valoader, lr=lr, batch_size=batch_size, num_epochs=num_epochs, corrupt=corrupt, loss_type=\"cross-entropy\")\n",
    "                else:\n",
    "                    dae.fit(trloader, valoader, lr=lr, batch_size=batch_size, num_epochs=num_epochs, corrupt=corrupt, loss_type=\"mse\")\n",
    "            data_x = dae.encodeBatch(trloader)\n",
    "            valid_x = dae.encodeBatch(valoader)\n",
    "            trainset = Dataset(data_x, data_x)\n",
    "            trloader = torch.utils.data.DataLoader(\n",
    "                trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "            validset = Dataset(valid_x, valid_x)\n",
    "            valoader = torch.utils.data.DataLoader(\n",
    "                validset, batch_size=1000, shuffle=False, num_workers=0)\n",
    "            daeLayers.append(dae)\n",
    "\n",
    "        self.copyParam(daeLayers)\n",
    "\n",
    "    def copyParam(self, daeLayers):\n",
    "        if self.dropout==0:\n",
    "            every = 2\n",
    "        else:\n",
    "            every = 3\n",
    "        # input layer\n",
    "        # copy encoder weight\n",
    "        self.encoder[0].weight.data.copy_(daeLayers[0].weight.data)\n",
    "        self.encoder[0].bias.data.copy_(daeLayers[0].bias.data)\n",
    "        self._dec.weight.data.copy_(daeLayers[0].deweight.data)\n",
    "        self._dec.bias.data.copy_(daeLayers[0].vbias.data)\n",
    "\n",
    "        for l in range(1, len(self.layers)-2):\n",
    "            # copy encoder weight\n",
    "            self.encoder[l*every].weight.data.copy_(daeLayers[l].weight.data)\n",
    "            self.encoder[l*every].bias.data.copy_(daeLayers[l].bias.data)\n",
    "\n",
    "            # copy decoder weight\n",
    "            self.decoder[-(l-1)*every-2].weight.data.copy_(daeLayers[l].deweight.data)\n",
    "            self.decoder[-(l-1)*every-2].bias.data.copy_(daeLayers[l].vbias.data)\n",
    "\n",
    "        # z layer\n",
    "        self._enc_mu.weight.data.copy_(daeLayers[-1].weight.data)\n",
    "        self._enc_mu.bias.data.copy_(daeLayers[-1].bias.data)\n",
    "        self.decoder[0].weight.data.copy_(daeLayers[-1].deweight.data)\n",
    "        self.decoder[0].bias.data.copy_(daeLayers[-1].vbias.data)\n",
    "\n",
    "    def fit(self, trainloader, validloader, lr=0.001, num_epochs=10, corrupt=0.3,\n",
    "        loss_type=\"mse\"):\n",
    "        \"\"\"\n",
    "        data_x: FloatTensor\n",
    "        valid_x: FloatTensor\n",
    "        \"\"\"\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        if use_cuda:\n",
    "            self.cuda()\n",
    "        print(\"=====Stacked Denoising Autoencoding Layer=======\")\n",
    "        # optimizer = optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=lr)\n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, self.parameters()), lr=lr, momentum=0.9)\n",
    "        if loss_type==\"mse\":\n",
    "            criterion = MSELoss()\n",
    "        elif loss_type==\"cross-entropy\":\n",
    "            criterion = BCELoss()\n",
    "\n",
    "        # validate\n",
    "        total_loss = 0.0\n",
    "        total_num = 0\n",
    "        for batch_idx, (inputs, _) in enumerate(validloader):\n",
    "            inputs = inputs.view(inputs.size(0), -1).float()\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "            inputs = Variable(inputs)\n",
    "            z, outputs = self.forward(inputs)\n",
    "\n",
    "            valid_recon_loss = criterion(outputs, inputs)\n",
    "            total_loss += valid_recon_loss.data * len(inputs)\n",
    "            total_num += inputs.size()[0]\n",
    "\n",
    "        valid_loss = total_loss / total_num\n",
    "        print(\"#Epoch 0: Valid Reconstruct Loss: %.4f\" % (valid_loss))\n",
    "        self.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            # train 1 epoch\n",
    "            adjust_learning_rate(lr, optimizer, epoch)\n",
    "            train_loss = 0.0\n",
    "            for batch_idx, (inputs, _) in enumerate(trainloader):\n",
    "                inputs = inputs.view(inputs.size(0), -1).float()\n",
    "                inputs_corr = masking_noise(inputs, corrupt)\n",
    "                if use_cuda:\n",
    "                    inputs = inputs.cuda()\n",
    "                    inputs_corr = inputs_corr.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                inputs = Variable(inputs)\n",
    "                inputs_corr = Variable(inputs_corr)\n",
    "\n",
    "                z, outputs = self.forward(inputs_corr)\n",
    "                recon_loss = criterion(outputs, inputs)\n",
    "                train_loss += recon_loss.data*len(inputs)\n",
    "                recon_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # validate\n",
    "            valid_loss = 0.0\n",
    "            for batch_idx, (inputs, _) in enumerate(validloader):\n",
    "                inputs = inputs.view(inputs.size(0), -1).float()\n",
    "                if use_cuda:\n",
    "                    inputs = inputs.cuda()\n",
    "                inputs = Variable(inputs)\n",
    "                z, outputs = self.forward(inputs)\n",
    "\n",
    "                valid_recon_loss = criterion(outputs, inputs)\n",
    "                valid_loss += valid_recon_loss.data * len(inputs)\n",
    "\n",
    "            print(\"#Epoch %3d: Reconstruct Loss: %.4f, Valid Reconstruct Loss: %.4f\" % (\n",
    "                epoch+1, train_loss / len(trainloader.dataset), valid_loss / len(validloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJIBPWdH3TVp",
    "outputId": "f039e2e2-5e2e-4f89-8a69-348b255da652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackedDAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=17770, out_features=500, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=500, out_features=2000, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=2000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2000, out_features=500, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (_enc_mu): Linear(in_features=2000, out_features=20, bias=True)\n",
      "  (_dec): Linear(in_features=500, out_features=17770, bias=True)\n",
      ")\n",
      "DenoisingAutoencoder(\n",
      "  in_features=17770, out_features=500, bias=True\n",
      "  (enc_act_func): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "=====Denoising Autoencoding layer=======\n",
      "#Epoch 0: Valid Reconstruct Loss: 0.4219\n",
      "#Epoch   1: Reconstruct Loss: 0.4198, Valid Reconstruct Loss: 0.4152\n",
      "#Epoch   2: Reconstruct Loss: 0.4125, Valid Reconstruct Loss: 0.3980\n",
      "#Epoch   3: Reconstruct Loss: 0.3911, Valid Reconstruct Loss: 0.3501\n",
      "#Epoch   4: Reconstruct Loss: 0.3412, Valid Reconstruct Loss: 0.2851\n",
      "#Epoch   5: Reconstruct Loss: 0.2891, Valid Reconstruct Loss: 0.2556\n",
      "#Epoch   6: Reconstruct Loss: 0.2627, Valid Reconstruct Loss: 0.2347\n",
      "#Epoch   7: Reconstruct Loss: 0.2437, Valid Reconstruct Loss: 0.2155\n",
      "#Epoch   8: Reconstruct Loss: 0.2231, Valid Reconstruct Loss: 0.1962\n",
      "#Epoch   9: Reconstruct Loss: 0.2067, Valid Reconstruct Loss: 0.1777\n",
      "#Epoch  10: Reconstruct Loss: 0.1834, Valid Reconstruct Loss: 0.1515\n",
      "#Epoch  11: Reconstruct Loss: 0.1622, Valid Reconstruct Loss: 0.1288\n",
      "#Epoch  12: Reconstruct Loss: 0.1428, Valid Reconstruct Loss: 0.1113\n",
      "#Epoch  13: Reconstruct Loss: 0.1239, Valid Reconstruct Loss: 0.0931\n",
      "#Epoch  14: Reconstruct Loss: 0.1086, Valid Reconstruct Loss: 0.0792\n",
      "#Epoch  15: Reconstruct Loss: 0.0947, Valid Reconstruct Loss: 0.0709\n",
      "#Epoch  16: Reconstruct Loss: 0.0856, Valid Reconstruct Loss: 0.0648\n",
      "#Epoch  17: Reconstruct Loss: 0.0781, Valid Reconstruct Loss: 0.0565\n",
      "#Epoch  18: Reconstruct Loss: 0.0738, Valid Reconstruct Loss: 0.0574\n",
      "#Epoch  19: Reconstruct Loss: 0.0698, Valid Reconstruct Loss: 0.0491\n",
      "#Epoch  20: Reconstruct Loss: 0.0666, Valid Reconstruct Loss: 0.0438\n",
      "#Epoch  21: Reconstruct Loss: 0.0577, Valid Reconstruct Loss: 0.0418\n",
      "#Epoch  22: Reconstruct Loss: 0.0518, Valid Reconstruct Loss: 0.0362\n",
      "#Epoch  23: Reconstruct Loss: 0.0492, Valid Reconstruct Loss: 0.0375\n",
      "#Epoch  24: Reconstruct Loss: 0.0444, Valid Reconstruct Loss: 0.0283\n",
      "#Epoch  25: Reconstruct Loss: 0.0411, Valid Reconstruct Loss: 0.0305\n",
      "#Epoch  26: Reconstruct Loss: 0.0392, Valid Reconstruct Loss: 0.0295\n",
      "#Epoch  27: Reconstruct Loss: 0.0369, Valid Reconstruct Loss: 0.0280\n",
      "#Epoch  28: Reconstruct Loss: 0.0370, Valid Reconstruct Loss: 0.0284\n",
      "#Epoch  29: Reconstruct Loss: 0.0362, Valid Reconstruct Loss: 0.0270\n",
      "#Epoch  30: Reconstruct Loss: 0.0391, Valid Reconstruct Loss: 0.0260\n",
      "#Epoch  31: Reconstruct Loss: 0.0370, Valid Reconstruct Loss: 0.0246\n",
      "#Epoch  32: Reconstruct Loss: 0.0418, Valid Reconstruct Loss: 0.0455\n",
      "#Epoch  33: Reconstruct Loss: 0.0414, Valid Reconstruct Loss: 0.0369\n",
      "#Epoch  34: Reconstruct Loss: 0.0385, Valid Reconstruct Loss: 0.0324\n",
      "#Epoch  35: Reconstruct Loss: 0.0365, Valid Reconstruct Loss: 0.0321\n",
      "#Epoch  36: Reconstruct Loss: 0.0467, Valid Reconstruct Loss: 0.0411\n",
      "#Epoch  37: Reconstruct Loss: 0.0474, Valid Reconstruct Loss: 0.0269\n",
      "#Epoch  38: Reconstruct Loss: 0.0553, Valid Reconstruct Loss: 0.0355\n",
      "#Epoch  39: Reconstruct Loss: 0.0362, Valid Reconstruct Loss: 0.0256\n",
      "#Epoch  40: Reconstruct Loss: 0.0314, Valid Reconstruct Loss: 0.0240\n",
      "#Epoch  41: Reconstruct Loss: 0.0294, Valid Reconstruct Loss: 0.0248\n",
      "#Epoch  42: Reconstruct Loss: 0.0286, Valid Reconstruct Loss: 0.0280\n",
      "#Epoch  43: Reconstruct Loss: 0.0278, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch  44: Reconstruct Loss: 0.0268, Valid Reconstruct Loss: 0.0263\n",
      "#Epoch  45: Reconstruct Loss: 0.0331, Valid Reconstruct Loss: 0.0295\n",
      "#Epoch  46: Reconstruct Loss: 0.0284, Valid Reconstruct Loss: 0.0259\n",
      "#Epoch  47: Reconstruct Loss: 0.0274, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch  48: Reconstruct Loss: 0.0261, Valid Reconstruct Loss: 0.0358\n",
      "#Epoch  49: Reconstruct Loss: 0.0288, Valid Reconstruct Loss: 0.0234\n",
      "#Epoch  50: Reconstruct Loss: 0.0346, Valid Reconstruct Loss: 0.0592\n",
      "#Epoch  51: Reconstruct Loss: 0.0308, Valid Reconstruct Loss: 0.0240\n",
      "#Epoch  52: Reconstruct Loss: 0.0289, Valid Reconstruct Loss: 0.0411\n",
      "#Epoch  53: Reconstruct Loss: 0.0275, Valid Reconstruct Loss: 0.0346\n",
      "#Epoch  54: Reconstruct Loss: 0.0288, Valid Reconstruct Loss: 0.0266\n",
      "#Epoch  55: Reconstruct Loss: 0.0361, Valid Reconstruct Loss: 0.0405\n",
      "#Epoch  56: Reconstruct Loss: 0.0331, Valid Reconstruct Loss: 0.0276\n",
      "#Epoch  57: Reconstruct Loss: 0.0282, Valid Reconstruct Loss: 0.0294\n",
      "#Epoch  58: Reconstruct Loss: 0.0268, Valid Reconstruct Loss: 0.0333\n",
      "#Epoch  59: Reconstruct Loss: 0.0266, Valid Reconstruct Loss: 0.0234\n",
      "#Epoch  60: Reconstruct Loss: 0.0272, Valid Reconstruct Loss: 0.0363\n",
      "#Epoch  61: Reconstruct Loss: 0.0257, Valid Reconstruct Loss: 0.0178\n",
      "#Epoch  62: Reconstruct Loss: 0.0234, Valid Reconstruct Loss: 0.0242\n",
      "#Epoch  63: Reconstruct Loss: 0.0233, Valid Reconstruct Loss: 0.0354\n",
      "#Epoch  64: Reconstruct Loss: 0.0247, Valid Reconstruct Loss: 0.0559\n",
      "#Epoch  65: Reconstruct Loss: 0.0329, Valid Reconstruct Loss: 0.0273\n",
      "#Epoch  66: Reconstruct Loss: 0.0351, Valid Reconstruct Loss: 0.0334\n",
      "#Epoch  67: Reconstruct Loss: 0.0326, Valid Reconstruct Loss: 0.0389\n",
      "#Epoch  68: Reconstruct Loss: 0.0347, Valid Reconstruct Loss: 0.0270\n",
      "#Epoch  69: Reconstruct Loss: 0.0311, Valid Reconstruct Loss: 0.0377\n",
      "#Epoch  70: Reconstruct Loss: 0.0279, Valid Reconstruct Loss: 0.0288\n",
      "#Epoch  71: Reconstruct Loss: 0.0290, Valid Reconstruct Loss: 0.0449\n",
      "#Epoch  72: Reconstruct Loss: 0.0260, Valid Reconstruct Loss: 0.0230\n",
      "#Epoch  73: Reconstruct Loss: 0.0350, Valid Reconstruct Loss: 0.0510\n",
      "#Epoch  74: Reconstruct Loss: 0.0393, Valid Reconstruct Loss: 0.0526\n",
      "#Epoch  75: Reconstruct Loss: 0.0451, Valid Reconstruct Loss: 0.0286\n",
      "#Epoch  76: Reconstruct Loss: 0.0304, Valid Reconstruct Loss: 0.0302\n",
      "#Epoch  77: Reconstruct Loss: 0.0258, Valid Reconstruct Loss: 0.0223\n",
      "#Epoch  78: Reconstruct Loss: 0.0235, Valid Reconstruct Loss: 0.0329\n",
      "#Epoch  79: Reconstruct Loss: 0.0296, Valid Reconstruct Loss: 0.0285\n",
      "#Epoch  80: Reconstruct Loss: 0.0280, Valid Reconstruct Loss: 0.0286\n",
      "#Epoch  81: Reconstruct Loss: 0.0348, Valid Reconstruct Loss: 0.0245\n",
      "#Epoch  82: Reconstruct Loss: 0.0238, Valid Reconstruct Loss: 0.0349\n",
      "#Epoch  83: Reconstruct Loss: 0.0267, Valid Reconstruct Loss: 0.0279\n",
      "#Epoch  84: Reconstruct Loss: 0.0252, Valid Reconstruct Loss: 0.0243\n",
      "#Epoch  85: Reconstruct Loss: 0.0300, Valid Reconstruct Loss: 0.0377\n",
      "#Epoch  86: Reconstruct Loss: 0.0223, Valid Reconstruct Loss: 0.0344\n",
      "#Epoch  87: Reconstruct Loss: 0.0221, Valid Reconstruct Loss: 0.0233\n",
      "#Epoch  88: Reconstruct Loss: 0.0193, Valid Reconstruct Loss: 0.0235\n",
      "#Epoch  89: Reconstruct Loss: 0.0216, Valid Reconstruct Loss: 0.0334\n",
      "#Epoch  90: Reconstruct Loss: 0.0256, Valid Reconstruct Loss: 0.0319\n",
      "#Epoch  91: Reconstruct Loss: 0.0296, Valid Reconstruct Loss: 0.0298\n",
      "#Epoch  92: Reconstruct Loss: 0.0219, Valid Reconstruct Loss: 0.0372\n",
      "#Epoch  93: Reconstruct Loss: 0.0190, Valid Reconstruct Loss: 0.0405\n",
      "#Epoch  94: Reconstruct Loss: 0.0196, Valid Reconstruct Loss: 0.0532\n",
      "#Epoch  95: Reconstruct Loss: 0.0209, Valid Reconstruct Loss: 0.0288\n",
      "#Epoch  96: Reconstruct Loss: 0.0224, Valid Reconstruct Loss: 0.0235\n",
      "#Epoch  97: Reconstruct Loss: 0.0226, Valid Reconstruct Loss: 0.0285\n",
      "#Epoch  98: Reconstruct Loss: 0.0190, Valid Reconstruct Loss: 0.0352\n",
      "#Epoch  99: Reconstruct Loss: 0.0383, Valid Reconstruct Loss: 0.0494\n",
      "#Epoch 100: Reconstruct Loss: 0.0458, Valid Reconstruct Loss: 0.0783\n",
      "Switching to learning rate 0.005000\n",
      "#Epoch 101: Reconstruct Loss: 0.0582, Valid Reconstruct Loss: 0.0622\n",
      "#Epoch 102: Reconstruct Loss: 0.0501, Valid Reconstruct Loss: 0.0402\n",
      "#Epoch 103: Reconstruct Loss: 0.0299, Valid Reconstruct Loss: 0.0337\n",
      "#Epoch 104: Reconstruct Loss: 0.0300, Valid Reconstruct Loss: 0.0298\n",
      "#Epoch 105: Reconstruct Loss: 0.0286, Valid Reconstruct Loss: 0.0260\n",
      "#Epoch 106: Reconstruct Loss: 0.0277, Valid Reconstruct Loss: 0.0251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 107: Reconstruct Loss: 0.0218, Valid Reconstruct Loss: 0.0248\n",
      "#Epoch 108: Reconstruct Loss: 0.0215, Valid Reconstruct Loss: 0.0246\n",
      "#Epoch 109: Reconstruct Loss: 0.0195, Valid Reconstruct Loss: 0.0235\n",
      "#Epoch 110: Reconstruct Loss: 0.0202, Valid Reconstruct Loss: 0.0236\n",
      "#Epoch 111: Reconstruct Loss: 0.0187, Valid Reconstruct Loss: 0.0235\n",
      "#Epoch 112: Reconstruct Loss: 0.0187, Valid Reconstruct Loss: 0.0236\n",
      "#Epoch 113: Reconstruct Loss: 0.0191, Valid Reconstruct Loss: 0.0209\n",
      "#Epoch 114: Reconstruct Loss: 0.0208, Valid Reconstruct Loss: 0.0206\n",
      "#Epoch 115: Reconstruct Loss: 0.0178, Valid Reconstruct Loss: 0.0212\n",
      "#Epoch 116: Reconstruct Loss: 0.0186, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 117: Reconstruct Loss: 0.0178, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 118: Reconstruct Loss: 0.0180, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 119: Reconstruct Loss: 0.0171, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 120: Reconstruct Loss: 0.0182, Valid Reconstruct Loss: 0.0224\n",
      "#Epoch 121: Reconstruct Loss: 0.0192, Valid Reconstruct Loss: 0.0234\n",
      "#Epoch 122: Reconstruct Loss: 0.0185, Valid Reconstruct Loss: 0.0236\n",
      "#Epoch 123: Reconstruct Loss: 0.0165, Valid Reconstruct Loss: 0.0231\n",
      "#Epoch 124: Reconstruct Loss: 0.0174, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 125: Reconstruct Loss: 0.0163, Valid Reconstruct Loss: 0.0223\n",
      "#Epoch 126: Reconstruct Loss: 0.0177, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 127: Reconstruct Loss: 0.0171, Valid Reconstruct Loss: 0.0208\n",
      "#Epoch 128: Reconstruct Loss: 0.0159, Valid Reconstruct Loss: 0.0207\n",
      "#Epoch 129: Reconstruct Loss: 0.0179, Valid Reconstruct Loss: 0.0207\n",
      "#Epoch 130: Reconstruct Loss: 0.0167, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 131: Reconstruct Loss: 0.0163, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 132: Reconstruct Loss: 0.0154, Valid Reconstruct Loss: 0.0208\n",
      "#Epoch 133: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0204\n",
      "#Epoch 134: Reconstruct Loss: 0.0174, Valid Reconstruct Loss: 0.0201\n",
      "#Epoch 135: Reconstruct Loss: 0.0170, Valid Reconstruct Loss: 0.0209\n",
      "#Epoch 136: Reconstruct Loss: 0.0167, Valid Reconstruct Loss: 0.0207\n",
      "#Epoch 137: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0209\n",
      "#Epoch 138: Reconstruct Loss: 0.0157, Valid Reconstruct Loss: 0.0211\n",
      "#Epoch 139: Reconstruct Loss: 0.0161, Valid Reconstruct Loss: 0.0208\n",
      "#Epoch 140: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0203\n",
      "#Epoch 141: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0190\n",
      "#Epoch 142: Reconstruct Loss: 0.0185, Valid Reconstruct Loss: 0.0200\n",
      "#Epoch 143: Reconstruct Loss: 0.0318, Valid Reconstruct Loss: 0.0214\n",
      "#Epoch 144: Reconstruct Loss: 0.0159, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 145: Reconstruct Loss: 0.0159, Valid Reconstruct Loss: 0.0210\n",
      "#Epoch 146: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0209\n",
      "#Epoch 147: Reconstruct Loss: 0.0154, Valid Reconstruct Loss: 0.0214\n",
      "#Epoch 148: Reconstruct Loss: 0.0180, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 149: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0222\n",
      "#Epoch 150: Reconstruct Loss: 0.0177, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 151: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0222\n",
      "#Epoch 152: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 153: Reconstruct Loss: 0.0179, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 154: Reconstruct Loss: 0.0155, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 155: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0215\n",
      "#Epoch 156: Reconstruct Loss: 0.0155, Valid Reconstruct Loss: 0.0210\n",
      "#Epoch 157: Reconstruct Loss: 0.0174, Valid Reconstruct Loss: 0.0206\n",
      "#Epoch 158: Reconstruct Loss: 0.0157, Valid Reconstruct Loss: 0.0222\n",
      "#Epoch 159: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 160: Reconstruct Loss: 0.0159, Valid Reconstruct Loss: 0.0207\n",
      "#Epoch 161: Reconstruct Loss: 0.0157, Valid Reconstruct Loss: 0.0214\n",
      "#Epoch 162: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 163: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0213\n",
      "#Epoch 164: Reconstruct Loss: 0.0146, Valid Reconstruct Loss: 0.0211\n",
      "#Epoch 165: Reconstruct Loss: 0.0155, Valid Reconstruct Loss: 0.0215\n",
      "#Epoch 166: Reconstruct Loss: 0.0149, Valid Reconstruct Loss: 0.0209\n",
      "#Epoch 167: Reconstruct Loss: 0.0160, Valid Reconstruct Loss: 0.0211\n",
      "#Epoch 168: Reconstruct Loss: 0.0160, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 169: Reconstruct Loss: 0.0228, Valid Reconstruct Loss: 0.0214\n",
      "#Epoch 170: Reconstruct Loss: 0.0155, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 171: Reconstruct Loss: 0.0161, Valid Reconstruct Loss: 0.0233\n",
      "#Epoch 172: Reconstruct Loss: 0.0145, Valid Reconstruct Loss: 0.0238\n",
      "#Epoch 173: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0236\n",
      "#Epoch 174: Reconstruct Loss: 0.0149, Valid Reconstruct Loss: 0.0240\n",
      "#Epoch 175: Reconstruct Loss: 0.0155, Valid Reconstruct Loss: 0.0245\n",
      "#Epoch 176: Reconstruct Loss: 0.0148, Valid Reconstruct Loss: 0.0236\n",
      "#Epoch 177: Reconstruct Loss: 0.0158, Valid Reconstruct Loss: 0.0230\n",
      "#Epoch 178: Reconstruct Loss: 0.0142, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 179: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0222\n",
      "#Epoch 180: Reconstruct Loss: 0.0143, Valid Reconstruct Loss: 0.0212\n",
      "#Epoch 181: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0209\n",
      "#Epoch 182: Reconstruct Loss: 0.0205, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 183: Reconstruct Loss: 0.0157, Valid Reconstruct Loss: 0.0231\n",
      "#Epoch 184: Reconstruct Loss: 0.0155, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 185: Reconstruct Loss: 0.0158, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 186: Reconstruct Loss: 0.0149, Valid Reconstruct Loss: 0.0212\n",
      "#Epoch 187: Reconstruct Loss: 0.0149, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 188: Reconstruct Loss: 0.0161, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 189: Reconstruct Loss: 0.0173, Valid Reconstruct Loss: 0.0224\n",
      "#Epoch 190: Reconstruct Loss: 0.0164, Valid Reconstruct Loss: 0.0206\n",
      "#Epoch 191: Reconstruct Loss: 0.0149, Valid Reconstruct Loss: 0.0206\n",
      "#Epoch 192: Reconstruct Loss: 0.0145, Valid Reconstruct Loss: 0.0213\n",
      "#Epoch 193: Reconstruct Loss: 0.0140, Valid Reconstruct Loss: 0.0224\n",
      "#Epoch 194: Reconstruct Loss: 0.0143, Valid Reconstruct Loss: 0.0223\n",
      "#Epoch 195: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0212\n",
      "#Epoch 196: Reconstruct Loss: 0.0230, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 197: Reconstruct Loss: 0.0167, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 198: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0240\n",
      "#Epoch 199: Reconstruct Loss: 0.0160, Valid Reconstruct Loss: 0.0230\n",
      "#Epoch 200: Reconstruct Loss: 0.0145, Valid Reconstruct Loss: 0.0231\n",
      "Switching to learning rate 0.000500\n",
      "#Epoch 201: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0231\n",
      "#Epoch 202: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0231\n",
      "#Epoch 203: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0229\n",
      "#Epoch 204: Reconstruct Loss: 0.0145, Valid Reconstruct Loss: 0.0228\n",
      "#Epoch 205: Reconstruct Loss: 0.0154, Valid Reconstruct Loss: 0.0229\n",
      "#Epoch 206: Reconstruct Loss: 0.0158, Valid Reconstruct Loss: 0.0230\n",
      "#Epoch 207: Reconstruct Loss: 0.0146, Valid Reconstruct Loss: 0.0229\n",
      "#Epoch 208: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0229\n",
      "#Epoch 209: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0228\n",
      "#Epoch 210: Reconstruct Loss: 0.0156, Valid Reconstruct Loss: 0.0229\n",
      "#Epoch 211: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0230\n",
      "#Epoch 212: Reconstruct Loss: 0.0145, Valid Reconstruct Loss: 0.0229\n",
      "#Epoch 213: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0228\n",
      "#Epoch 214: Reconstruct Loss: 0.0154, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 215: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 216: Reconstruct Loss: 0.0158, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 217: Reconstruct Loss: 0.0141, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 218: Reconstruct Loss: 0.0217, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 219: Reconstruct Loss: 0.0143, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 220: Reconstruct Loss: 0.0156, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 221: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 222: Reconstruct Loss: 0.0149, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 223: Reconstruct Loss: 0.0165, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 224: Reconstruct Loss: 0.0138, Valid Reconstruct Loss: 0.0227\n",
      "#Epoch 225: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 226: Reconstruct Loss: 0.0161, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 227: Reconstruct Loss: 0.0148, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 228: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 229: Reconstruct Loss: 0.0144, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 230: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0226\n",
      "#Epoch 231: Reconstruct Loss: 0.0156, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 232: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0223\n",
      "#Epoch 233: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0222\n",
      "#Epoch 234: Reconstruct Loss: 0.0146, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 235: Reconstruct Loss: 0.0143, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 236: Reconstruct Loss: 0.0199, Valid Reconstruct Loss: 0.0223\n",
      "#Epoch 237: Reconstruct Loss: 0.0144, Valid Reconstruct Loss: 0.0223\n",
      "#Epoch 238: Reconstruct Loss: 0.0159, Valid Reconstruct Loss: 0.0224\n",
      "#Epoch 239: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 240: Reconstruct Loss: 0.0142, Valid Reconstruct Loss: 0.0224\n",
      "#Epoch 241: Reconstruct Loss: 0.0156, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 242: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0224\n",
      "#Epoch 243: Reconstruct Loss: 0.0168, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 244: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0225\n",
      "#Epoch 245: Reconstruct Loss: 0.0142, Valid Reconstruct Loss: 0.0222\n",
      "#Epoch 246: Reconstruct Loss: 0.0138, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 247: Reconstruct Loss: 0.0140, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 248: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 249: Reconstruct Loss: 0.0148, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 250: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 251: Reconstruct Loss: 0.0167, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 252: Reconstruct Loss: 0.0154, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 253: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 254: Reconstruct Loss: 0.0179, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 255: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 256: Reconstruct Loss: 0.0154, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 257: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 258: Reconstruct Loss: 0.0146, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 259: Reconstruct Loss: 0.0142, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 260: Reconstruct Loss: 0.0144, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 261: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 262: Reconstruct Loss: 0.0148, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 263: Reconstruct Loss: 0.0140, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 264: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 265: Reconstruct Loss: 0.0141, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 266: Reconstruct Loss: 0.0139, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 267: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 268: Reconstruct Loss: 0.0152, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 269: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 270: Reconstruct Loss: 0.0172, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 271: Reconstruct Loss: 0.0142, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 272: Reconstruct Loss: 0.0141, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 273: Reconstruct Loss: 0.0143, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 274: Reconstruct Loss: 0.0142, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 275: Reconstruct Loss: 0.0154, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 276: Reconstruct Loss: 0.0150, Valid Reconstruct Loss: 0.0215\n",
      "#Epoch 277: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0214\n",
      "#Epoch 278: Reconstruct Loss: 0.0155, Valid Reconstruct Loss: 0.0215\n",
      "#Epoch 279: Reconstruct Loss: 0.0184, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 280: Reconstruct Loss: 0.0158, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 281: Reconstruct Loss: 0.0142, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 282: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 283: Reconstruct Loss: 0.0145, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 284: Reconstruct Loss: 0.0151, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 285: Reconstruct Loss: 0.0148, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 286: Reconstruct Loss: 0.0141, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 287: Reconstruct Loss: 0.0153, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 288: Reconstruct Loss: 0.0164, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 289: Reconstruct Loss: 0.0148, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 290: Reconstruct Loss: 0.0156, Valid Reconstruct Loss: 0.0221\n",
      "#Epoch 291: Reconstruct Loss: 0.0139, Valid Reconstruct Loss: 0.0220\n",
      "#Epoch 292: Reconstruct Loss: 0.0159, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 293: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 294: Reconstruct Loss: 0.0159, Valid Reconstruct Loss: 0.0216\n",
      "#Epoch 295: Reconstruct Loss: 0.0139, Valid Reconstruct Loss: 0.0217\n",
      "#Epoch 296: Reconstruct Loss: 0.0165, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 297: Reconstruct Loss: 0.0199, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 298: Reconstruct Loss: 0.0157, Valid Reconstruct Loss: 0.0219\n",
      "#Epoch 299: Reconstruct Loss: 0.0156, Valid Reconstruct Loss: 0.0218\n",
      "#Epoch 300: Reconstruct Loss: 0.0147, Valid Reconstruct Loss: 0.0219\n",
      "DenoisingAutoencoder(\n",
      "  in_features=500, out_features=500, bias=True\n",
      "  (enc_act_func): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "=====Denoising Autoencoding layer=======\n",
      "#Epoch 0: Valid Reconstruct Loss: 5.0723\n",
      "#Epoch   1: Reconstruct Loss: 4.3609, Valid Reconstruct Loss: 3.5666\n",
      "#Epoch   2: Reconstruct Loss: 2.5699, Valid Reconstruct Loss: 2.1103\n",
      "#Epoch   3: Reconstruct Loss: 7.5050, Valid Reconstruct Loss: 6018.9453\n",
      "#Epoch   4: Reconstruct Loss: 406433.5000, Valid Reconstruct Loss: 835.3807\n",
      "#Epoch   5: Reconstruct Loss: 1115.1193, Valid Reconstruct Loss: 12.4843\n",
      "#Epoch   6: Reconstruct Loss: 8.4435, Valid Reconstruct Loss: 17.7237\n",
      "#Epoch   7: Reconstruct Loss: 11.8753, Valid Reconstruct Loss: 3.7308\n",
      "#Epoch   8: Reconstruct Loss: 4.2466, Valid Reconstruct Loss: 4.0921\n",
      "#Epoch   9: Reconstruct Loss: 4.3932, Valid Reconstruct Loss: 3.2473\n",
      "#Epoch  10: Reconstruct Loss: 4.7779, Valid Reconstruct Loss: 303.6033\n",
      "#Epoch  11: Reconstruct Loss: 32.9270, Valid Reconstruct Loss: 3.6196\n",
      "#Epoch  12: Reconstruct Loss: 4.2706, Valid Reconstruct Loss: 3.9200\n",
      "#Epoch  13: Reconstruct Loss: 4.3517, Valid Reconstruct Loss: 3.9668\n",
      "#Epoch  14: Reconstruct Loss: 4.9130, Valid Reconstruct Loss: 4.1137\n",
      "#Epoch  15: Reconstruct Loss: 4.7700, Valid Reconstruct Loss: 7.3009\n",
      "#Epoch  16: Reconstruct Loss: 8.1374, Valid Reconstruct Loss: 5.2832\n",
      "#Epoch  17: Reconstruct Loss: 5.3777, Valid Reconstruct Loss: 4.1671\n",
      "#Epoch  18: Reconstruct Loss: 4.8719, Valid Reconstruct Loss: 4.6106\n",
      "#Epoch  19: Reconstruct Loss: 4.4074, Valid Reconstruct Loss: 4.1513\n",
      "#Epoch  20: Reconstruct Loss: 5.0478, Valid Reconstruct Loss: 4.1928\n",
      "#Epoch  21: Reconstruct Loss: 4.1831, Valid Reconstruct Loss: 8.6364\n",
      "#Epoch  22: Reconstruct Loss: 10.6824, Valid Reconstruct Loss: 281.7512\n",
      "#Epoch  23: Reconstruct Loss: 5.2158, Valid Reconstruct Loss: 5.1979\n",
      "#Epoch  24: Reconstruct Loss: 5.1788, Valid Reconstruct Loss: 4.9299\n",
      "#Epoch  25: Reconstruct Loss: 4.8987, Valid Reconstruct Loss: 5.0917\n",
      "#Epoch  26: Reconstruct Loss: 5.1274, Valid Reconstruct Loss: 5.1081\n",
      "#Epoch  27: Reconstruct Loss: 5.0024, Valid Reconstruct Loss: 4.3940\n",
      "#Epoch  28: Reconstruct Loss: 4.9507, Valid Reconstruct Loss: 4.7778\n",
      "#Epoch  29: Reconstruct Loss: 4.6210, Valid Reconstruct Loss: 4.4763\n",
      "#Epoch  30: Reconstruct Loss: 5.0307, Valid Reconstruct Loss: 5.0206\n",
      "#Epoch  31: Reconstruct Loss: 5.0097, Valid Reconstruct Loss: 4.9958\n",
      "#Epoch  32: Reconstruct Loss: 5.1409, Valid Reconstruct Loss: 4.9649\n",
      "#Epoch  33: Reconstruct Loss: 4.8208, Valid Reconstruct Loss: 5.7370\n",
      "#Epoch  34: Reconstruct Loss: 5.7534, Valid Reconstruct Loss: 4.8896\n",
      "#Epoch  35: Reconstruct Loss: 213.2283, Valid Reconstruct Loss: 4.5485\n",
      "#Epoch  36: Reconstruct Loss: 4.6509, Valid Reconstruct Loss: 4.9097\n",
      "#Epoch  37: Reconstruct Loss: 4.9012, Valid Reconstruct Loss: 4.8909\n",
      "#Epoch  38: Reconstruct Loss: 4.8818, Valid Reconstruct Loss: 4.8714\n",
      "#Epoch  39: Reconstruct Loss: 4.8629, Valid Reconstruct Loss: 4.8530\n",
      "#Epoch  40: Reconstruct Loss: 4.8448, Valid Reconstruct Loss: 4.8352\n",
      "#Epoch  41: Reconstruct Loss: 4.6950, Valid Reconstruct Loss: 4.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch  42: Reconstruct Loss: 4.7780, Valid Reconstruct Loss: 4.4770\n",
      "#Epoch  43: Reconstruct Loss: 4.8830, Valid Reconstruct Loss: 4.7932\n",
      "#Epoch  44: Reconstruct Loss: 4.7865, Valid Reconstruct Loss: 4.7780\n",
      "#Epoch  45: Reconstruct Loss: 4.7712, Valid Reconstruct Loss: 4.7611\n",
      "#Epoch  46: Reconstruct Loss: 4.7479, Valid Reconstruct Loss: 4.6953\n",
      "#Epoch  47: Reconstruct Loss: 4.5548, Valid Reconstruct Loss: 4.1126\n",
      "#Epoch  48: Reconstruct Loss: 4.1469, Valid Reconstruct Loss: 4.0822\n",
      "#Epoch  49: Reconstruct Loss: 4.4467, Valid Reconstruct Loss: 4.4692\n",
      "#Epoch  50: Reconstruct Loss: 4.7265, Valid Reconstruct Loss: 5.3826\n",
      "#Epoch  51: Reconstruct Loss: 4.7162, Valid Reconstruct Loss: 5.2181\n",
      "#Epoch  52: Reconstruct Loss: 5.2084, Valid Reconstruct Loss: 4.6975\n",
      "#Epoch  53: Reconstruct Loss: 4.6929, Valid Reconstruct Loss: 4.6876\n",
      "#Epoch  54: Reconstruct Loss: 4.6831, Valid Reconstruct Loss: 4.6779\n",
      "#Epoch  55: Reconstruct Loss: 4.6735, Valid Reconstruct Loss: 4.6639\n",
      "#Epoch  56: Reconstruct Loss: 4.4743, Valid Reconstruct Loss: 4.3256\n",
      "#Epoch  57: Reconstruct Loss: 4.6299, Valid Reconstruct Loss: 5.1346\n",
      "#Epoch  58: Reconstruct Loss: 5.5068, Valid Reconstruct Loss: 4.6452\n",
      "#Epoch  59: Reconstruct Loss: 4.6213, Valid Reconstruct Loss: 4.4448\n",
      "#Epoch  60: Reconstruct Loss: 4.3496, Valid Reconstruct Loss: 4.4766\n",
      "#Epoch  61: Reconstruct Loss: 4.6010, Valid Reconstruct Loss: 4.6292\n",
      "#Epoch  62: Reconstruct Loss: 4.6261, Valid Reconstruct Loss: 4.6225\n",
      "#Epoch  63: Reconstruct Loss: 4.6195, Valid Reconstruct Loss: 4.6160\n",
      "#Epoch  64: Reconstruct Loss: 4.5934, Valid Reconstruct Loss: 4.0861\n",
      "#Epoch  65: Reconstruct Loss: 4.6302, Valid Reconstruct Loss: 4.6052\n",
      "#Epoch  66: Reconstruct Loss: 4.6027, Valid Reconstruct Loss: 4.5997\n",
      "#Epoch  67: Reconstruct Loss: 4.5972, Valid Reconstruct Loss: 4.5943\n",
      "#Epoch  68: Reconstruct Loss: 4.5919, Valid Reconstruct Loss: 4.5890\n",
      "#Epoch  69: Reconstruct Loss: 4.5868, Valid Reconstruct Loss: 4.5841\n",
      "#Epoch  70: Reconstruct Loss: 4.5820, Valid Reconstruct Loss: 4.5794\n",
      "#Epoch  71: Reconstruct Loss: 4.5772, Valid Reconstruct Loss: 4.5748\n",
      "#Epoch  72: Reconstruct Loss: 4.5728, Valid Reconstruct Loss: 4.5704\n",
      "#Epoch  73: Reconstruct Loss: 4.5686, Valid Reconstruct Loss: 4.5664\n",
      "#Epoch  74: Reconstruct Loss: 4.5646, Valid Reconstruct Loss: 4.5624\n",
      "#Epoch  75: Reconstruct Loss: 4.5607, Valid Reconstruct Loss: 4.5587\n",
      "#Epoch  76: Reconstruct Loss: 4.5569, Valid Reconstruct Loss: 4.5545\n",
      "#Epoch  77: Reconstruct Loss: 4.5533, Valid Reconstruct Loss: 4.5519\n",
      "#Epoch  78: Reconstruct Loss: 4.5504, Valid Reconstruct Loss: 4.5488\n",
      "#Epoch  79: Reconstruct Loss: 4.5474, Valid Reconstruct Loss: 4.5457\n",
      "#Epoch  80: Reconstruct Loss: 4.5442, Valid Reconstruct Loss: 4.5416\n",
      "#Epoch  81: Reconstruct Loss: 4.4837, Valid Reconstruct Loss: 4.0149\n",
      "#Epoch  82: Reconstruct Loss: 4.1669, Valid Reconstruct Loss: 4.2192\n",
      "#Epoch  83: Reconstruct Loss: 4.7216, Valid Reconstruct Loss: 4.5388\n",
      "#Epoch  84: Reconstruct Loss: 4.5374, Valid Reconstruct Loss: 4.5221\n",
      "#Epoch  85: Reconstruct Loss: 4.4718, Valid Reconstruct Loss: 4.1418\n",
      "#Epoch  86: Reconstruct Loss: 4.0774, Valid Reconstruct Loss: 3.9406\n",
      "#Epoch  87: Reconstruct Loss: 4.4686, Valid Reconstruct Loss: 4.5947\n",
      "#Epoch  88: Reconstruct Loss: 4.5331, Valid Reconstruct Loss: 4.5297\n",
      "#Epoch  89: Reconstruct Loss: 4.5287, Valid Reconstruct Loss: 4.5276\n",
      "#Epoch  90: Reconstruct Loss: 4.5267, Valid Reconstruct Loss: 4.5256\n",
      "#Epoch  91: Reconstruct Loss: 4.5246, Valid Reconstruct Loss: 4.5235\n",
      "#Epoch  92: Reconstruct Loss: 4.5227, Valid Reconstruct Loss: 4.5217\n",
      "#Epoch  93: Reconstruct Loss: 4.5209, Valid Reconstruct Loss: 4.5199\n",
      "#Epoch  94: Reconstruct Loss: 4.5189, Valid Reconstruct Loss: 4.5167\n",
      "#Epoch  95: Reconstruct Loss: 4.2930, Valid Reconstruct Loss: 4.5061\n",
      "#Epoch  96: Reconstruct Loss: 4.5166, Valid Reconstruct Loss: 4.5157\n",
      "#Epoch  97: Reconstruct Loss: 4.5150, Valid Reconstruct Loss: 4.5142\n",
      "#Epoch  98: Reconstruct Loss: 4.5135, Valid Reconstruct Loss: 4.5127\n",
      "#Epoch  99: Reconstruct Loss: 4.4883, Valid Reconstruct Loss: 4.0290\n",
      "#Epoch 100: Reconstruct Loss: 4.2141, Valid Reconstruct Loss: 10.0060\n",
      "Switching to learning rate 0.005000\n",
      "#Epoch 101: Reconstruct Loss: 11.9638, Valid Reconstruct Loss: 4.6583\n",
      "#Epoch 102: Reconstruct Loss: 4.5115, Valid Reconstruct Loss: 4.5108\n",
      "#Epoch 103: Reconstruct Loss: 4.5103, Valid Reconstruct Loss: 4.5081\n",
      "#Epoch 104: Reconstruct Loss: 4.5037, Valid Reconstruct Loss: 4.4821\n",
      "#Epoch 105: Reconstruct Loss: 4.4476, Valid Reconstruct Loss: 4.2617\n",
      "#Epoch 106: Reconstruct Loss: 4.0944, Valid Reconstruct Loss: 3.2614\n",
      "#Epoch 107: Reconstruct Loss: 3.3672, Valid Reconstruct Loss: 4.0733\n",
      "#Epoch 108: Reconstruct Loss: 4.7871, Valid Reconstruct Loss: 3.8637\n",
      "#Epoch 109: Reconstruct Loss: 4.0609, Valid Reconstruct Loss: 3.8546\n",
      "#Epoch 110: Reconstruct Loss: 3.9441, Valid Reconstruct Loss: 3.8200\n",
      "#Epoch 111: Reconstruct Loss: 3.9039, Valid Reconstruct Loss: 3.8067\n",
      "#Epoch 112: Reconstruct Loss: 3.9896, Valid Reconstruct Loss: 3.7970\n",
      "#Epoch 113: Reconstruct Loss: 3.9017, Valid Reconstruct Loss: 3.7756\n",
      "#Epoch 114: Reconstruct Loss: 3.8381, Valid Reconstruct Loss: 3.8033\n",
      "#Epoch 115: Reconstruct Loss: 4.2696, Valid Reconstruct Loss: 3.9784\n",
      "#Epoch 116: Reconstruct Loss: 3.9184, Valid Reconstruct Loss: 3.6405\n",
      "#Epoch 117: Reconstruct Loss: 3.9056, Valid Reconstruct Loss: 3.4402\n",
      "#Epoch 118: Reconstruct Loss: 3.5938, Valid Reconstruct Loss: 3.2616\n",
      "#Epoch 119: Reconstruct Loss: 3.6975, Valid Reconstruct Loss: 3.2240\n",
      "#Epoch 120: Reconstruct Loss: 3.4216, Valid Reconstruct Loss: 2.6139\n",
      "#Epoch 121: Reconstruct Loss: 3.5523, Valid Reconstruct Loss: 2.4880\n",
      "#Epoch 122: Reconstruct Loss: 2.8129, Valid Reconstruct Loss: 2.8948\n",
      "#Epoch 123: Reconstruct Loss: 3.4496, Valid Reconstruct Loss: 2.9073\n",
      "#Epoch 124: Reconstruct Loss: 3.6510, Valid Reconstruct Loss: 3.2580\n",
      "#Epoch 125: Reconstruct Loss: 3.5048, Valid Reconstruct Loss: 3.2016\n",
      "#Epoch 126: Reconstruct Loss: 3.4817, Valid Reconstruct Loss: 3.1596\n",
      "#Epoch 127: Reconstruct Loss: 3.6437, Valid Reconstruct Loss: 3.1222\n",
      "#Epoch 128: Reconstruct Loss: 3.5976, Valid Reconstruct Loss: 3.1147\n",
      "#Epoch 129: Reconstruct Loss: 3.3853, Valid Reconstruct Loss: 2.8880\n",
      "#Epoch 130: Reconstruct Loss: 3.5132, Valid Reconstruct Loss: 2.8964\n",
      "#Epoch 131: Reconstruct Loss: 3.2633, Valid Reconstruct Loss: 3.0188\n",
      "#Epoch 132: Reconstruct Loss: 3.3544, Valid Reconstruct Loss: 2.7240\n",
      "#Epoch 133: Reconstruct Loss: 3.1515, Valid Reconstruct Loss: 2.6655\n",
      "#Epoch 134: Reconstruct Loss: 3.2743, Valid Reconstruct Loss: 8.2854\n",
      "#Epoch 135: Reconstruct Loss: 10.5582, Valid Reconstruct Loss: 3.3984\n",
      "#Epoch 136: Reconstruct Loss: 3.5938, Valid Reconstruct Loss: 3.3160\n",
      "#Epoch 137: Reconstruct Loss: 3.5328, Valid Reconstruct Loss: 3.2800\n",
      "#Epoch 138: Reconstruct Loss: 3.4273, Valid Reconstruct Loss: 3.2523\n",
      "#Epoch 139: Reconstruct Loss: 3.5407, Valid Reconstruct Loss: 3.2436\n",
      "#Epoch 140: Reconstruct Loss: 3.7261, Valid Reconstruct Loss: 3.2375\n",
      "#Epoch 141: Reconstruct Loss: 3.4098, Valid Reconstruct Loss: 3.2250\n",
      "#Epoch 142: Reconstruct Loss: 3.5076, Valid Reconstruct Loss: 3.2078\n",
      "#Epoch 143: Reconstruct Loss: 3.7020, Valid Reconstruct Loss: 3.2463\n",
      "#Epoch 144: Reconstruct Loss: 3.5380, Valid Reconstruct Loss: 3.6605\n",
      "#Epoch 145: Reconstruct Loss: 5.1330, Valid Reconstruct Loss: 3.9897\n",
      "#Epoch 146: Reconstruct Loss: 3.8917, Valid Reconstruct Loss: 3.8083\n",
      "#Epoch 147: Reconstruct Loss: 3.9040, Valid Reconstruct Loss: 3.8040\n",
      "#Epoch 148: Reconstruct Loss: 3.9352, Valid Reconstruct Loss: 3.8022\n",
      "#Epoch 149: Reconstruct Loss: 3.8979, Valid Reconstruct Loss: 3.8043\n",
      "#Epoch 150: Reconstruct Loss: 4.1499, Valid Reconstruct Loss: 3.7889\n",
      "#Epoch 151: Reconstruct Loss: 3.8879, Valid Reconstruct Loss: 3.7852\n",
      "#Epoch 152: Reconstruct Loss: 4.1604, Valid Reconstruct Loss: 3.7841\n",
      "#Epoch 153: Reconstruct Loss: 3.8960, Valid Reconstruct Loss: 3.7748\n",
      "#Epoch 154: Reconstruct Loss: 3.8820, Valid Reconstruct Loss: 3.7643\n",
      "#Epoch 155: Reconstruct Loss: 3.8875, Valid Reconstruct Loss: 3.7591\n",
      "#Epoch 156: Reconstruct Loss: 3.9575, Valid Reconstruct Loss: 3.7455\n",
      "#Epoch 157: Reconstruct Loss: 4.1080, Valid Reconstruct Loss: 3.7239\n",
      "#Epoch 158: Reconstruct Loss: 3.8423, Valid Reconstruct Loss: 3.7248\n",
      "#Epoch 159: Reconstruct Loss: 3.8498, Valid Reconstruct Loss: 3.7081\n",
      "#Epoch 160: Reconstruct Loss: 3.8155, Valid Reconstruct Loss: 3.7118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 161: Reconstruct Loss: 3.7956, Valid Reconstruct Loss: 3.6937\n",
      "#Epoch 162: Reconstruct Loss: 3.8139, Valid Reconstruct Loss: 3.6690\n",
      "#Epoch 163: Reconstruct Loss: 3.7872, Valid Reconstruct Loss: 3.6501\n",
      "#Epoch 164: Reconstruct Loss: 3.8043, Valid Reconstruct Loss: 3.6408\n",
      "#Epoch 165: Reconstruct Loss: 3.7646, Valid Reconstruct Loss: 3.6326\n",
      "#Epoch 166: Reconstruct Loss: 3.8139, Valid Reconstruct Loss: 3.6168\n",
      "#Epoch 167: Reconstruct Loss: 3.8595, Valid Reconstruct Loss: 3.6311\n",
      "#Epoch 168: Reconstruct Loss: 3.7584, Valid Reconstruct Loss: 3.6185\n",
      "#Epoch 169: Reconstruct Loss: 3.7395, Valid Reconstruct Loss: 3.6152\n",
      "#Epoch 170: Reconstruct Loss: 3.7986, Valid Reconstruct Loss: 3.6032\n",
      "#Epoch 171: Reconstruct Loss: 3.7580, Valid Reconstruct Loss: 3.5980\n",
      "#Epoch 172: Reconstruct Loss: 3.7187, Valid Reconstruct Loss: 3.5905\n",
      "#Epoch 173: Reconstruct Loss: 3.7151, Valid Reconstruct Loss: 3.5790\n",
      "#Epoch 174: Reconstruct Loss: 3.6893, Valid Reconstruct Loss: 3.5676\n",
      "#Epoch 175: Reconstruct Loss: 3.7710, Valid Reconstruct Loss: 3.5684\n",
      "#Epoch 176: Reconstruct Loss: 3.7055, Valid Reconstruct Loss: 3.5390\n",
      "#Epoch 177: Reconstruct Loss: 4.0476, Valid Reconstruct Loss: 4.0820\n",
      "#Epoch 178: Reconstruct Loss: 4.1537, Valid Reconstruct Loss: 3.9224\n",
      "#Epoch 179: Reconstruct Loss: 3.9318, Valid Reconstruct Loss: 3.7666\n",
      "#Epoch 180: Reconstruct Loss: 4.0009, Valid Reconstruct Loss: 3.6340\n",
      "#Epoch 181: Reconstruct Loss: 3.7854, Valid Reconstruct Loss: 3.5550\n",
      "#Epoch 182: Reconstruct Loss: 3.8184, Valid Reconstruct Loss: 3.4971\n",
      "#Epoch 183: Reconstruct Loss: 3.7703, Valid Reconstruct Loss: 3.4669\n",
      "#Epoch 184: Reconstruct Loss: 3.7017, Valid Reconstruct Loss: 3.4320\n",
      "#Epoch 185: Reconstruct Loss: 3.6307, Valid Reconstruct Loss: 3.4082\n",
      "#Epoch 186: Reconstruct Loss: 3.8256, Valid Reconstruct Loss: 3.4009\n",
      "#Epoch 187: Reconstruct Loss: 3.6672, Valid Reconstruct Loss: 3.3699\n",
      "#Epoch 188: Reconstruct Loss: 3.5415, Valid Reconstruct Loss: 3.3321\n",
      "#Epoch 189: Reconstruct Loss: 3.5647, Valid Reconstruct Loss: 3.3242\n",
      "#Epoch 190: Reconstruct Loss: 3.6182, Valid Reconstruct Loss: 3.3167\n",
      "#Epoch 191: Reconstruct Loss: 3.5643, Valid Reconstruct Loss: 3.2996\n",
      "#Epoch 192: Reconstruct Loss: 3.4959, Valid Reconstruct Loss: 3.2787\n",
      "#Epoch 193: Reconstruct Loss: 3.4914, Valid Reconstruct Loss: 3.2813\n",
      "#Epoch 194: Reconstruct Loss: 3.5984, Valid Reconstruct Loss: 3.2944\n",
      "#Epoch 195: Reconstruct Loss: 3.4684, Valid Reconstruct Loss: 3.2807\n",
      "#Epoch 196: Reconstruct Loss: 3.4755, Valid Reconstruct Loss: 3.2694\n",
      "#Epoch 197: Reconstruct Loss: 3.4812, Valid Reconstruct Loss: 3.2670\n",
      "#Epoch 198: Reconstruct Loss: 3.4446, Valid Reconstruct Loss: 3.2653\n",
      "#Epoch 199: Reconstruct Loss: 3.5238, Valid Reconstruct Loss: 3.2681\n",
      "#Epoch 200: Reconstruct Loss: 3.4096, Valid Reconstruct Loss: 3.2664\n",
      "Switching to learning rate 0.000500\n",
      "#Epoch 201: Reconstruct Loss: 3.4315, Valid Reconstruct Loss: 3.2641\n",
      "#Epoch 202: Reconstruct Loss: 3.5662, Valid Reconstruct Loss: 3.2625\n",
      "#Epoch 203: Reconstruct Loss: 3.5205, Valid Reconstruct Loss: 3.2619\n",
      "#Epoch 204: Reconstruct Loss: 3.5200, Valid Reconstruct Loss: 3.2624\n",
      "#Epoch 205: Reconstruct Loss: 3.4440, Valid Reconstruct Loss: 3.2612\n",
      "#Epoch 206: Reconstruct Loss: 3.5707, Valid Reconstruct Loss: 3.2622\n",
      "#Epoch 207: Reconstruct Loss: 3.4399, Valid Reconstruct Loss: 3.2623\n",
      "#Epoch 208: Reconstruct Loss: 3.4135, Valid Reconstruct Loss: 3.2611\n",
      "#Epoch 209: Reconstruct Loss: 3.5368, Valid Reconstruct Loss: 3.2601\n",
      "#Epoch 210: Reconstruct Loss: 3.6703, Valid Reconstruct Loss: 3.2599\n",
      "#Epoch 211: Reconstruct Loss: 3.4805, Valid Reconstruct Loss: 3.2576\n",
      "#Epoch 212: Reconstruct Loss: 3.3989, Valid Reconstruct Loss: 3.2567\n",
      "#Epoch 213: Reconstruct Loss: 3.4090, Valid Reconstruct Loss: 3.2557\n",
      "#Epoch 214: Reconstruct Loss: 3.5019, Valid Reconstruct Loss: 3.2548\n",
      "#Epoch 215: Reconstruct Loss: 3.4316, Valid Reconstruct Loss: 3.2545\n",
      "#Epoch 216: Reconstruct Loss: 3.4556, Valid Reconstruct Loss: 3.2542\n",
      "#Epoch 217: Reconstruct Loss: 3.7985, Valid Reconstruct Loss: 3.2534\n",
      "#Epoch 218: Reconstruct Loss: 3.4020, Valid Reconstruct Loss: 3.2529\n",
      "#Epoch 219: Reconstruct Loss: 3.7166, Valid Reconstruct Loss: 3.2526\n",
      "#Epoch 220: Reconstruct Loss: 3.5007, Valid Reconstruct Loss: 3.2521\n",
      "#Epoch 221: Reconstruct Loss: 3.5111, Valid Reconstruct Loss: 3.2521\n",
      "#Epoch 222: Reconstruct Loss: 3.4113, Valid Reconstruct Loss: 3.2521\n",
      "#Epoch 223: Reconstruct Loss: 3.4262, Valid Reconstruct Loss: 3.2516\n",
      "#Epoch 224: Reconstruct Loss: 3.6308, Valid Reconstruct Loss: 3.2517\n",
      "#Epoch 225: Reconstruct Loss: 3.4465, Valid Reconstruct Loss: 3.2512\n",
      "#Epoch 226: Reconstruct Loss: 3.3808, Valid Reconstruct Loss: 3.2513\n",
      "#Epoch 227: Reconstruct Loss: 3.4399, Valid Reconstruct Loss: 3.2515\n",
      "#Epoch 228: Reconstruct Loss: 3.5168, Valid Reconstruct Loss: 3.2513\n",
      "#Epoch 229: Reconstruct Loss: 3.4099, Valid Reconstruct Loss: 3.2512\n",
      "#Epoch 230: Reconstruct Loss: 3.5324, Valid Reconstruct Loss: 3.2515\n",
      "#Epoch 231: Reconstruct Loss: 3.5866, Valid Reconstruct Loss: 3.2512\n",
      "#Epoch 232: Reconstruct Loss: 3.4400, Valid Reconstruct Loss: 3.2510\n",
      "#Epoch 233: Reconstruct Loss: 3.3978, Valid Reconstruct Loss: 3.2512\n",
      "#Epoch 234: Reconstruct Loss: 3.4432, Valid Reconstruct Loss: 3.2297\n",
      "#Epoch 235: Reconstruct Loss: 3.3697, Valid Reconstruct Loss: 3.2021\n",
      "#Epoch 236: Reconstruct Loss: 3.4506, Valid Reconstruct Loss: 3.1831\n",
      "#Epoch 237: Reconstruct Loss: 3.4919, Valid Reconstruct Loss: 3.1725\n",
      "#Epoch 238: Reconstruct Loss: 3.3165, Valid Reconstruct Loss: 3.1583\n",
      "#Epoch 239: Reconstruct Loss: 3.4334, Valid Reconstruct Loss: 3.1382\n",
      "#Epoch 240: Reconstruct Loss: 3.4394, Valid Reconstruct Loss: 3.1360\n",
      "#Epoch 241: Reconstruct Loss: 3.3365, Valid Reconstruct Loss: 3.1299\n",
      "#Epoch 242: Reconstruct Loss: 3.3486, Valid Reconstruct Loss: 3.1105\n",
      "#Epoch 243: Reconstruct Loss: 3.3005, Valid Reconstruct Loss: 3.0930\n",
      "#Epoch 244: Reconstruct Loss: 3.3500, Valid Reconstruct Loss: 3.0813\n",
      "#Epoch 245: Reconstruct Loss: 3.6441, Valid Reconstruct Loss: 3.0630\n",
      "#Epoch 246: Reconstruct Loss: 3.5139, Valid Reconstruct Loss: 3.0567\n",
      "#Epoch 247: Reconstruct Loss: 3.4148, Valid Reconstruct Loss: 3.0621\n",
      "#Epoch 248: Reconstruct Loss: 3.2665, Valid Reconstruct Loss: 3.0576\n",
      "#Epoch 249: Reconstruct Loss: 3.1868, Valid Reconstruct Loss: 3.0369\n",
      "#Epoch 250: Reconstruct Loss: 3.2987, Valid Reconstruct Loss: 3.0237\n",
      "#Epoch 251: Reconstruct Loss: 3.4781, Valid Reconstruct Loss: 3.0237\n",
      "#Epoch 252: Reconstruct Loss: 3.2839, Valid Reconstruct Loss: 3.0055\n",
      "#Epoch 253: Reconstruct Loss: 3.2510, Valid Reconstruct Loss: 2.9947\n",
      "#Epoch 254: Reconstruct Loss: 3.1232, Valid Reconstruct Loss: 2.9784\n",
      "#Epoch 255: Reconstruct Loss: 3.1717, Valid Reconstruct Loss: 2.9612\n",
      "#Epoch 256: Reconstruct Loss: 3.1801, Valid Reconstruct Loss: 2.9450\n",
      "#Epoch 257: Reconstruct Loss: 3.1301, Valid Reconstruct Loss: 2.9271\n",
      "#Epoch 258: Reconstruct Loss: 3.2558, Valid Reconstruct Loss: 2.9116\n",
      "#Epoch 259: Reconstruct Loss: 3.4829, Valid Reconstruct Loss: 2.9092\n",
      "#Epoch 260: Reconstruct Loss: 3.0674, Valid Reconstruct Loss: 2.9110\n",
      "#Epoch 261: Reconstruct Loss: 3.3734, Valid Reconstruct Loss: 2.8870\n",
      "#Epoch 262: Reconstruct Loss: 3.3431, Valid Reconstruct Loss: 2.8706\n",
      "#Epoch 263: Reconstruct Loss: 3.0736, Valid Reconstruct Loss: 2.8591\n",
      "#Epoch 264: Reconstruct Loss: 3.0108, Valid Reconstruct Loss: 2.8538\n",
      "#Epoch 265: Reconstruct Loss: 3.0488, Valid Reconstruct Loss: 2.8473\n",
      "#Epoch 266: Reconstruct Loss: 3.3522, Valid Reconstruct Loss: 2.8290\n",
      "#Epoch 267: Reconstruct Loss: 3.0987, Valid Reconstruct Loss: 2.8252\n",
      "#Epoch 268: Reconstruct Loss: 3.0732, Valid Reconstruct Loss: 2.8139\n",
      "#Epoch 269: Reconstruct Loss: 2.9721, Valid Reconstruct Loss: 2.8010\n",
      "#Epoch 270: Reconstruct Loss: 3.3324, Valid Reconstruct Loss: 2.8258\n",
      "#Epoch 271: Reconstruct Loss: 7.1087, Valid Reconstruct Loss: 3.1482\n",
      "#Epoch 272: Reconstruct Loss: 3.2033, Valid Reconstruct Loss: 2.7959\n",
      "#Epoch 273: Reconstruct Loss: 2.9658, Valid Reconstruct Loss: 2.7771\n",
      "#Epoch 274: Reconstruct Loss: 3.8195, Valid Reconstruct Loss: 2.7679\n",
      "#Epoch 275: Reconstruct Loss: 3.8533, Valid Reconstruct Loss: 2.7633\n",
      "#Epoch 276: Reconstruct Loss: 2.8724, Valid Reconstruct Loss: 2.7696\n",
      "#Epoch 277: Reconstruct Loss: 3.8499, Valid Reconstruct Loss: 2.7678\n",
      "#Epoch 278: Reconstruct Loss: 2.9360, Valid Reconstruct Loss: 2.7589\n",
      "#Epoch 279: Reconstruct Loss: 2.9462, Valid Reconstruct Loss: 2.7601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 280: Reconstruct Loss: 3.0194, Valid Reconstruct Loss: 2.7564\n",
      "#Epoch 281: Reconstruct Loss: 2.8943, Valid Reconstruct Loss: 2.7589\n",
      "#Epoch 282: Reconstruct Loss: 3.1589, Valid Reconstruct Loss: 2.7564\n",
      "#Epoch 283: Reconstruct Loss: 2.9189, Valid Reconstruct Loss: 2.7567\n",
      "#Epoch 284: Reconstruct Loss: 2.8602, Valid Reconstruct Loss: 2.7570\n",
      "#Epoch 285: Reconstruct Loss: 3.3164, Valid Reconstruct Loss: 2.7603\n",
      "#Epoch 286: Reconstruct Loss: 2.9225, Valid Reconstruct Loss: 2.7558\n",
      "#Epoch 287: Reconstruct Loss: 2.9064, Valid Reconstruct Loss: 2.7564\n",
      "#Epoch 288: Reconstruct Loss: 2.8469, Valid Reconstruct Loss: 2.7542\n",
      "#Epoch 289: Reconstruct Loss: 2.8863, Valid Reconstruct Loss: 2.7537\n",
      "#Epoch 290: Reconstruct Loss: 2.8937, Valid Reconstruct Loss: 2.7550\n",
      "#Epoch 291: Reconstruct Loss: 3.2100, Valid Reconstruct Loss: 2.7574\n",
      "#Epoch 292: Reconstruct Loss: 2.8411, Valid Reconstruct Loss: 2.7692\n",
      "#Epoch 293: Reconstruct Loss: 2.8451, Valid Reconstruct Loss: 2.7660\n",
      "#Epoch 294: Reconstruct Loss: 2.9780, Valid Reconstruct Loss: 2.7536\n",
      "#Epoch 295: Reconstruct Loss: 2.8774, Valid Reconstruct Loss: 2.7546\n",
      "#Epoch 296: Reconstruct Loss: 2.9069, Valid Reconstruct Loss: 2.7543\n",
      "#Epoch 297: Reconstruct Loss: 3.1498, Valid Reconstruct Loss: 2.7534\n",
      "#Epoch 298: Reconstruct Loss: 3.7339, Valid Reconstruct Loss: 2.7576\n",
      "#Epoch 299: Reconstruct Loss: 2.9512, Valid Reconstruct Loss: 2.7524\n",
      "#Epoch 300: Reconstruct Loss: 2.9370, Valid Reconstruct Loss: 2.7521\n",
      "DenoisingAutoencoder(\n",
      "  in_features=500, out_features=2000, bias=True\n",
      "  (enc_act_func): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "=====Denoising Autoencoding layer=======\n",
      "#Epoch 0: Valid Reconstruct Loss: 1.2857\n",
      "#Epoch   1: Reconstruct Loss: 1.4134, Valid Reconstruct Loss: 1.8772\n",
      "#Epoch   2: Reconstruct Loss: 0.9350, Valid Reconstruct Loss: 0.0689\n",
      "#Epoch   3: Reconstruct Loss: 0.0932, Valid Reconstruct Loss: 0.8834\n",
      "#Epoch   4: Reconstruct Loss: 1.6846, Valid Reconstruct Loss: 22.1923\n",
      "#Epoch   5: Reconstruct Loss: 11.4555, Valid Reconstruct Loss: 30.3673\n",
      "#Epoch   6: Reconstruct Loss: 17.6894, Valid Reconstruct Loss: 0.3709\n",
      "#Epoch   7: Reconstruct Loss: 0.1318, Valid Reconstruct Loss: 0.4946\n",
      "#Epoch   8: Reconstruct Loss: 2.5451, Valid Reconstruct Loss: 1.1334\n",
      "#Epoch   9: Reconstruct Loss: 1.1359, Valid Reconstruct Loss: 0.0361\n",
      "#Epoch  10: Reconstruct Loss: 0.6912, Valid Reconstruct Loss: 0.7813\n",
      "#Epoch  11: Reconstruct Loss: 1.0266, Valid Reconstruct Loss: 0.0197\n",
      "#Epoch  12: Reconstruct Loss: 0.8235, Valid Reconstruct Loss: 2.8507\n",
      "#Epoch  13: Reconstruct Loss: 2.6391, Valid Reconstruct Loss: 1.0597\n",
      "#Epoch  14: Reconstruct Loss: 3.3221, Valid Reconstruct Loss: 10.5787\n",
      "#Epoch  15: Reconstruct Loss: 9.2502, Valid Reconstruct Loss: 1.2261\n",
      "#Epoch  16: Reconstruct Loss: 1.8717, Valid Reconstruct Loss: 0.7644\n",
      "#Epoch  17: Reconstruct Loss: 0.3559, Valid Reconstruct Loss: 1.0071\n",
      "#Epoch  18: Reconstruct Loss: 1.8958, Valid Reconstruct Loss: 5.9736\n",
      "#Epoch  19: Reconstruct Loss: 1.5398, Valid Reconstruct Loss: 1.1150\n",
      "#Epoch  20: Reconstruct Loss: 0.9599, Valid Reconstruct Loss: 5.1381\n",
      "#Epoch  21: Reconstruct Loss: 0.6924, Valid Reconstruct Loss: 0.8972\n",
      "#Epoch  22: Reconstruct Loss: 3.3427, Valid Reconstruct Loss: 1.0625\n",
      "#Epoch  23: Reconstruct Loss: 0.3033, Valid Reconstruct Loss: 0.8094\n",
      "#Epoch  24: Reconstruct Loss: 1.2025, Valid Reconstruct Loss: 0.0859\n",
      "#Epoch  25: Reconstruct Loss: 0.4774, Valid Reconstruct Loss: 14.1628\n",
      "#Epoch  26: Reconstruct Loss: 2.0806, Valid Reconstruct Loss: 1.0383\n",
      "#Epoch  27: Reconstruct Loss: 1.0556, Valid Reconstruct Loss: 0.4631\n",
      "#Epoch  28: Reconstruct Loss: 0.2908, Valid Reconstruct Loss: 0.7666\n",
      "#Epoch  29: Reconstruct Loss: 0.7393, Valid Reconstruct Loss: 0.0143\n",
      "#Epoch  30: Reconstruct Loss: 0.9107, Valid Reconstruct Loss: 0.0272\n",
      "#Epoch  31: Reconstruct Loss: 0.8880, Valid Reconstruct Loss: 0.0387\n",
      "#Epoch  32: Reconstruct Loss: 0.4079, Valid Reconstruct Loss: 0.8404\n",
      "#Epoch  33: Reconstruct Loss: 1.0005, Valid Reconstruct Loss: 0.0991\n",
      "#Epoch  34: Reconstruct Loss: 0.4306, Valid Reconstruct Loss: 1.0449\n",
      "#Epoch  35: Reconstruct Loss: 1.0152, Valid Reconstruct Loss: 0.1012\n",
      "#Epoch  36: Reconstruct Loss: 2.4484, Valid Reconstruct Loss: 0.7990\n",
      "#Epoch  37: Reconstruct Loss: 0.9631, Valid Reconstruct Loss: 0.1778\n",
      "#Epoch  38: Reconstruct Loss: 1.0173, Valid Reconstruct Loss: 0.0463\n",
      "#Epoch  39: Reconstruct Loss: 0.9489, Valid Reconstruct Loss: 2.4042\n",
      "#Epoch  40: Reconstruct Loss: 0.3411, Valid Reconstruct Loss: 1.1756\n",
      "#Epoch  41: Reconstruct Loss: 1.0093, Valid Reconstruct Loss: 0.0447\n",
      "#Epoch  42: Reconstruct Loss: 0.7225, Valid Reconstruct Loss: 1.0162\n",
      "#Epoch  43: Reconstruct Loss: 0.9491, Valid Reconstruct Loss: 0.0935\n",
      "#Epoch  44: Reconstruct Loss: 1.1951, Valid Reconstruct Loss: 0.8662\n",
      "#Epoch  45: Reconstruct Loss: 0.2325, Valid Reconstruct Loss: 1.1131\n",
      "#Epoch  46: Reconstruct Loss: 1.8958, Valid Reconstruct Loss: 31.7344\n",
      "#Epoch  47: Reconstruct Loss: 1.5382, Valid Reconstruct Loss: 1.1921\n",
      "#Epoch  48: Reconstruct Loss: 2.0379, Valid Reconstruct Loss: 1.1377\n",
      "#Epoch  49: Reconstruct Loss: 1.1722, Valid Reconstruct Loss: 0.0925\n",
      "#Epoch  50: Reconstruct Loss: 0.2902, Valid Reconstruct Loss: 1.0170\n",
      "#Epoch  51: Reconstruct Loss: 1.1352, Valid Reconstruct Loss: 0.5195\n",
      "#Epoch  52: Reconstruct Loss: 0.9541, Valid Reconstruct Loss: 0.0413\n",
      "#Epoch  53: Reconstruct Loss: 1.0523, Valid Reconstruct Loss: 0.0529\n",
      "#Epoch  54: Reconstruct Loss: 0.3477, Valid Reconstruct Loss: 1.0077\n",
      "#Epoch  55: Reconstruct Loss: 1.6312, Valid Reconstruct Loss: 5.2682\n",
      "#Epoch  56: Reconstruct Loss: 1.7153, Valid Reconstruct Loss: 1.0167\n",
      "#Epoch  57: Reconstruct Loss: 0.9910, Valid Reconstruct Loss: 12.3575\n",
      "#Epoch  58: Reconstruct Loss: 1.6437, Valid Reconstruct Loss: 11.2385\n",
      "#Epoch  59: Reconstruct Loss: 1.0209, Valid Reconstruct Loss: 72.1245\n",
      "#Epoch  60: Reconstruct Loss: 4.5525, Valid Reconstruct Loss: 1.0168\n",
      "#Epoch  61: Reconstruct Loss: 1.0755, Valid Reconstruct Loss: 1.0083\n",
      "#Epoch  62: Reconstruct Loss: 1.0489, Valid Reconstruct Loss: 1.0173\n",
      "#Epoch  63: Reconstruct Loss: 1.0544, Valid Reconstruct Loss: 1.0112\n",
      "#Epoch  64: Reconstruct Loss: 1.0725, Valid Reconstruct Loss: 1.0086\n",
      "#Epoch  65: Reconstruct Loss: 1.1529, Valid Reconstruct Loss: 1.0105\n",
      "#Epoch  66: Reconstruct Loss: 1.1402, Valid Reconstruct Loss: 0.9483\n",
      "#Epoch  67: Reconstruct Loss: 1.0282, Valid Reconstruct Loss: 0.0757\n",
      "#Epoch  68: Reconstruct Loss: 1.4145, Valid Reconstruct Loss: 1.0015\n",
      "#Epoch  69: Reconstruct Loss: 1.0252, Valid Reconstruct Loss: 0.0169\n",
      "#Epoch  70: Reconstruct Loss: 0.9976, Valid Reconstruct Loss: 0.0417\n",
      "#Epoch  71: Reconstruct Loss: 0.2188, Valid Reconstruct Loss: 1.0837\n",
      "#Epoch  72: Reconstruct Loss: 1.1088, Valid Reconstruct Loss: 1.0022\n",
      "#Epoch  73: Reconstruct Loss: 1.1885, Valid Reconstruct Loss: 1.0393\n",
      "#Epoch  74: Reconstruct Loss: 1.0530, Valid Reconstruct Loss: 1.0564\n",
      "#Epoch  75: Reconstruct Loss: 1.0664, Valid Reconstruct Loss: 0.8884\n",
      "#Epoch  76: Reconstruct Loss: 1.0863, Valid Reconstruct Loss: 0.0238\n",
      "#Epoch  77: Reconstruct Loss: 0.2751, Valid Reconstruct Loss: 0.4008\n",
      "#Epoch  78: Reconstruct Loss: 0.9984, Valid Reconstruct Loss: 0.0252\n",
      "#Epoch  79: Reconstruct Loss: 0.9550, Valid Reconstruct Loss: 0.1142\n",
      "#Epoch  80: Reconstruct Loss: 0.2389, Valid Reconstruct Loss: 0.8951\n",
      "#Epoch  81: Reconstruct Loss: 1.0412, Valid Reconstruct Loss: 0.8379\n",
      "#Epoch  82: Reconstruct Loss: 1.0964, Valid Reconstruct Loss: 0.2730\n",
      "#Epoch  83: Reconstruct Loss: 0.9881, Valid Reconstruct Loss: 0.1079\n",
      "#Epoch  84: Reconstruct Loss: 0.9333, Valid Reconstruct Loss: 0.0421\n",
      "#Epoch  85: Reconstruct Loss: 0.1882, Valid Reconstruct Loss: 1.0278\n",
      "#Epoch  86: Reconstruct Loss: 1.0374, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch  87: Reconstruct Loss: 1.0620, Valid Reconstruct Loss: 1.3822\n",
      "#Epoch  88: Reconstruct Loss: 0.4652, Valid Reconstruct Loss: 1.0099\n",
      "#Epoch  89: Reconstruct Loss: 1.1073, Valid Reconstruct Loss: 0.9933\n",
      "#Epoch  90: Reconstruct Loss: 1.0291, Valid Reconstruct Loss: 0.3566\n",
      "#Epoch  91: Reconstruct Loss: 0.1838, Valid Reconstruct Loss: 0.9431\n",
      "#Epoch  92: Reconstruct Loss: 1.0599, Valid Reconstruct Loss: 0.9882\n",
      "#Epoch  93: Reconstruct Loss: 1.1186, Valid Reconstruct Loss: 0.5816\n",
      "#Epoch  94: Reconstruct Loss: 0.3517, Valid Reconstruct Loss: 1.0319\n",
      "#Epoch  95: Reconstruct Loss: 1.0993, Valid Reconstruct Loss: 1.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch  96: Reconstruct Loss: 1.0257, Valid Reconstruct Loss: 0.0295\n",
      "#Epoch  97: Reconstruct Loss: 0.5203, Valid Reconstruct Loss: 509.6964\n",
      "#Epoch  98: Reconstruct Loss: 3.2549, Valid Reconstruct Loss: 1.0223\n",
      "#Epoch  99: Reconstruct Loss: 1.0518, Valid Reconstruct Loss: 0.5296\n",
      "#Epoch 100: Reconstruct Loss: 0.3375, Valid Reconstruct Loss: 2.9516\n",
      "Switching to learning rate 0.005000\n",
      "#Epoch 101: Reconstruct Loss: 1.2132, Valid Reconstruct Loss: 1.0072\n",
      "#Epoch 102: Reconstruct Loss: 1.0607, Valid Reconstruct Loss: 1.0016\n",
      "#Epoch 103: Reconstruct Loss: 1.0391, Valid Reconstruct Loss: 1.0045\n",
      "#Epoch 104: Reconstruct Loss: 1.0838, Valid Reconstruct Loss: 0.9998\n",
      "#Epoch 105: Reconstruct Loss: 1.0415, Valid Reconstruct Loss: 1.0029\n",
      "#Epoch 106: Reconstruct Loss: 1.0423, Valid Reconstruct Loss: 1.0016\n",
      "#Epoch 107: Reconstruct Loss: 1.0663, Valid Reconstruct Loss: 0.9994\n",
      "#Epoch 108: Reconstruct Loss: 1.1396, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 109: Reconstruct Loss: 1.0461, Valid Reconstruct Loss: 1.0000\n",
      "#Epoch 110: Reconstruct Loss: 1.0605, Valid Reconstruct Loss: 0.9993\n",
      "#Epoch 111: Reconstruct Loss: 1.0725, Valid Reconstruct Loss: 1.0024\n",
      "#Epoch 112: Reconstruct Loss: 1.0404, Valid Reconstruct Loss: 0.9846\n",
      "#Epoch 113: Reconstruct Loss: 1.0179, Valid Reconstruct Loss: 0.9155\n",
      "#Epoch 114: Reconstruct Loss: 0.9048, Valid Reconstruct Loss: 0.5898\n",
      "#Epoch 115: Reconstruct Loss: 0.6448, Valid Reconstruct Loss: 0.5190\n",
      "#Epoch 116: Reconstruct Loss: 0.9937, Valid Reconstruct Loss: 0.0272\n",
      "#Epoch 117: Reconstruct Loss: 0.1585, Valid Reconstruct Loss: 0.1333\n",
      "#Epoch 118: Reconstruct Loss: 1.0312, Valid Reconstruct Loss: 0.1131\n",
      "#Epoch 119: Reconstruct Loss: 0.1469, Valid Reconstruct Loss: 0.0247\n",
      "#Epoch 120: Reconstruct Loss: 0.2836, Valid Reconstruct Loss: 0.8421\n",
      "#Epoch 121: Reconstruct Loss: 0.9302, Valid Reconstruct Loss: 0.5750\n",
      "#Epoch 122: Reconstruct Loss: 0.4190, Valid Reconstruct Loss: 0.5547\n",
      "#Epoch 123: Reconstruct Loss: 1.0977, Valid Reconstruct Loss: 0.0097\n",
      "#Epoch 124: Reconstruct Loss: 0.9382, Valid Reconstruct Loss: 0.0598\n",
      "#Epoch 125: Reconstruct Loss: 0.8816, Valid Reconstruct Loss: 0.0626\n",
      "#Epoch 126: Reconstruct Loss: 0.9672, Valid Reconstruct Loss: 0.0618\n",
      "#Epoch 127: Reconstruct Loss: 0.8927, Valid Reconstruct Loss: 0.0441\n",
      "#Epoch 128: Reconstruct Loss: 0.1909, Valid Reconstruct Loss: 0.0540\n",
      "#Epoch 129: Reconstruct Loss: 1.0458, Valid Reconstruct Loss: 0.0623\n",
      "#Epoch 130: Reconstruct Loss: 0.8945, Valid Reconstruct Loss: 0.0560\n",
      "#Epoch 131: Reconstruct Loss: 0.2474, Valid Reconstruct Loss: 0.0232\n",
      "#Epoch 132: Reconstruct Loss: 0.9155, Valid Reconstruct Loss: 0.0331\n",
      "#Epoch 133: Reconstruct Loss: 0.2424, Valid Reconstruct Loss: 0.0515\n",
      "#Epoch 134: Reconstruct Loss: 0.1319, Valid Reconstruct Loss: 0.0412\n",
      "#Epoch 135: Reconstruct Loss: 0.1832, Valid Reconstruct Loss: 0.1494\n",
      "#Epoch 136: Reconstruct Loss: 1.0236, Valid Reconstruct Loss: 0.1849\n",
      "#Epoch 137: Reconstruct Loss: 0.9229, Valid Reconstruct Loss: 0.1217\n",
      "#Epoch 138: Reconstruct Loss: 0.1488, Valid Reconstruct Loss: 0.0206\n",
      "#Epoch 139: Reconstruct Loss: 0.2204, Valid Reconstruct Loss: 0.6428\n",
      "#Epoch 140: Reconstruct Loss: 0.5615, Valid Reconstruct Loss: 0.3765\n",
      "#Epoch 141: Reconstruct Loss: 1.0124, Valid Reconstruct Loss: 0.0304\n",
      "#Epoch 142: Reconstruct Loss: 0.1992, Valid Reconstruct Loss: 0.1617\n",
      "#Epoch 143: Reconstruct Loss: 0.9526, Valid Reconstruct Loss: 0.3271\n",
      "#Epoch 144: Reconstruct Loss: 0.9267, Valid Reconstruct Loss: 0.1898\n",
      "#Epoch 145: Reconstruct Loss: 0.1741, Valid Reconstruct Loss: 0.0500\n",
      "#Epoch 146: Reconstruct Loss: 0.9362, Valid Reconstruct Loss: 0.0094\n",
      "#Epoch 147: Reconstruct Loss: 0.9160, Valid Reconstruct Loss: 0.0285\n",
      "#Epoch 148: Reconstruct Loss: 0.9268, Valid Reconstruct Loss: 0.0501\n",
      "#Epoch 149: Reconstruct Loss: 0.1079, Valid Reconstruct Loss: 0.0409\n",
      "#Epoch 150: Reconstruct Loss: 0.2348, Valid Reconstruct Loss: 0.0625\n",
      "#Epoch 151: Reconstruct Loss: 0.9086, Valid Reconstruct Loss: 0.0552\n",
      "#Epoch 152: Reconstruct Loss: 0.9998, Valid Reconstruct Loss: 0.0525\n",
      "#Epoch 153: Reconstruct Loss: 0.1076, Valid Reconstruct Loss: 0.0349\n",
      "#Epoch 154: Reconstruct Loss: 0.0861, Valid Reconstruct Loss: 0.1124\n",
      "#Epoch 155: Reconstruct Loss: 0.1854, Valid Reconstruct Loss: 0.0190\n",
      "#Epoch 156: Reconstruct Loss: 0.9412, Valid Reconstruct Loss: 0.0079\n",
      "#Epoch 157: Reconstruct Loss: 0.0950, Valid Reconstruct Loss: 0.0747\n",
      "#Epoch 158: Reconstruct Loss: 0.8925, Valid Reconstruct Loss: 0.1525\n",
      "#Epoch 159: Reconstruct Loss: 0.1916, Valid Reconstruct Loss: 0.0400\n",
      "#Epoch 160: Reconstruct Loss: 0.1375, Valid Reconstruct Loss: 0.1948\n",
      "#Epoch 161: Reconstruct Loss: 0.1726, Valid Reconstruct Loss: 0.0099\n",
      "#Epoch 162: Reconstruct Loss: 1.0446, Valid Reconstruct Loss: 0.0150\n",
      "#Epoch 163: Reconstruct Loss: 0.9394, Valid Reconstruct Loss: 0.0332\n",
      "#Epoch 164: Reconstruct Loss: 1.0439, Valid Reconstruct Loss: 0.0503\n",
      "#Epoch 165: Reconstruct Loss: 0.1245, Valid Reconstruct Loss: 0.0376\n",
      "#Epoch 166: Reconstruct Loss: 0.8854, Valid Reconstruct Loss: 0.0449\n",
      "#Epoch 167: Reconstruct Loss: 0.9011, Valid Reconstruct Loss: 0.0541\n",
      "#Epoch 168: Reconstruct Loss: 0.9271, Valid Reconstruct Loss: 0.0489\n",
      "#Epoch 169: Reconstruct Loss: 0.1045, Valid Reconstruct Loss: 0.0566\n",
      "#Epoch 170: Reconstruct Loss: 0.1073, Valid Reconstruct Loss: 0.0332\n",
      "#Epoch 171: Reconstruct Loss: 0.8820, Valid Reconstruct Loss: 0.0441\n",
      "#Epoch 172: Reconstruct Loss: 0.1749, Valid Reconstruct Loss: 0.0683\n",
      "#Epoch 173: Reconstruct Loss: 0.1642, Valid Reconstruct Loss: 0.0205\n",
      "#Epoch 174: Reconstruct Loss: 0.2630, Valid Reconstruct Loss: 0.6789\n",
      "#Epoch 175: Reconstruct Loss: 1.0349, Valid Reconstruct Loss: 0.7862\n",
      "#Epoch 176: Reconstruct Loss: 0.9938, Valid Reconstruct Loss: 0.6745\n",
      "#Epoch 177: Reconstruct Loss: 1.0979, Valid Reconstruct Loss: 0.5655\n",
      "#Epoch 178: Reconstruct Loss: 0.4893, Valid Reconstruct Loss: 0.0300\n",
      "#Epoch 179: Reconstruct Loss: 1.0088, Valid Reconstruct Loss: 0.0890\n",
      "#Epoch 180: Reconstruct Loss: 0.9116, Valid Reconstruct Loss: 0.0314\n",
      "#Epoch 181: Reconstruct Loss: 0.9454, Valid Reconstruct Loss: 0.0568\n",
      "#Epoch 182: Reconstruct Loss: 0.9470, Valid Reconstruct Loss: 0.0596\n",
      "#Epoch 183: Reconstruct Loss: 0.1507, Valid Reconstruct Loss: 0.0261\n",
      "#Epoch 184: Reconstruct Loss: 0.1032, Valid Reconstruct Loss: 0.2010\n",
      "#Epoch 185: Reconstruct Loss: 0.2339, Valid Reconstruct Loss: 0.1038\n",
      "#Epoch 186: Reconstruct Loss: 0.1989, Valid Reconstruct Loss: 0.0642\n",
      "#Epoch 187: Reconstruct Loss: 0.1418, Valid Reconstruct Loss: 0.5728\n",
      "#Epoch 188: Reconstruct Loss: 0.9928, Valid Reconstruct Loss: 0.4694\n",
      "#Epoch 189: Reconstruct Loss: 1.0304, Valid Reconstruct Loss: 0.2949\n",
      "#Epoch 190: Reconstruct Loss: 0.1475, Valid Reconstruct Loss: 0.0131\n",
      "#Epoch 191: Reconstruct Loss: 0.9620, Valid Reconstruct Loss: 0.0588\n",
      "#Epoch 192: Reconstruct Loss: 0.3898, Valid Reconstruct Loss: 0.9961\n",
      "#Epoch 193: Reconstruct Loss: 1.0551, Valid Reconstruct Loss: 0.9745\n",
      "#Epoch 194: Reconstruct Loss: 1.0063, Valid Reconstruct Loss: 0.8789\n",
      "#Epoch 195: Reconstruct Loss: 0.5720, Valid Reconstruct Loss: 0.1474\n",
      "#Epoch 196: Reconstruct Loss: 0.6826, Valid Reconstruct Loss: 1.0003\n",
      "#Epoch 197: Reconstruct Loss: 1.1403, Valid Reconstruct Loss: 1.0019\n",
      "#Epoch 198: Reconstruct Loss: 1.0450, Valid Reconstruct Loss: 0.9999\n",
      "#Epoch 199: Reconstruct Loss: 1.0525, Valid Reconstruct Loss: 0.9997\n",
      "#Epoch 200: Reconstruct Loss: 1.1271, Valid Reconstruct Loss: 0.9994\n",
      "Switching to learning rate 0.000500\n",
      "#Epoch 201: Reconstruct Loss: 1.0288, Valid Reconstruct Loss: 0.9994\n",
      "#Epoch 202: Reconstruct Loss: 1.0405, Valid Reconstruct Loss: 0.9993\n",
      "#Epoch 203: Reconstruct Loss: 1.0391, Valid Reconstruct Loss: 0.9993\n",
      "#Epoch 204: Reconstruct Loss: 1.0423, Valid Reconstruct Loss: 0.9993\n",
      "#Epoch 205: Reconstruct Loss: 1.0301, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 206: Reconstruct Loss: 1.0384, Valid Reconstruct Loss: 0.9997\n",
      "#Epoch 207: Reconstruct Loss: 1.0297, Valid Reconstruct Loss: 1.0000\n",
      "#Epoch 208: Reconstruct Loss: 1.0497, Valid Reconstruct Loss: 1.0001\n",
      "#Epoch 209: Reconstruct Loss: 1.1431, Valid Reconstruct Loss: 1.0003\n",
      "#Epoch 210: Reconstruct Loss: 1.0339, Valid Reconstruct Loss: 1.0002\n",
      "#Epoch 211: Reconstruct Loss: 1.0341, Valid Reconstruct Loss: 1.0005\n",
      "#Epoch 212: Reconstruct Loss: 1.0532, Valid Reconstruct Loss: 1.0004\n",
      "#Epoch 213: Reconstruct Loss: 1.0403, Valid Reconstruct Loss: 1.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 214: Reconstruct Loss: 1.0299, Valid Reconstruct Loss: 1.0004\n",
      "#Epoch 215: Reconstruct Loss: 1.0306, Valid Reconstruct Loss: 1.0003\n",
      "#Epoch 216: Reconstruct Loss: 1.0316, Valid Reconstruct Loss: 1.0004\n",
      "#Epoch 217: Reconstruct Loss: 1.0555, Valid Reconstruct Loss: 1.0005\n",
      "#Epoch 218: Reconstruct Loss: 1.0521, Valid Reconstruct Loss: 1.0005\n",
      "#Epoch 219: Reconstruct Loss: 1.1531, Valid Reconstruct Loss: 1.0004\n",
      "#Epoch 220: Reconstruct Loss: 1.0349, Valid Reconstruct Loss: 1.0009\n",
      "#Epoch 221: Reconstruct Loss: 1.0533, Valid Reconstruct Loss: 1.0018\n",
      "#Epoch 222: Reconstruct Loss: 1.0613, Valid Reconstruct Loss: 1.0011\n",
      "#Epoch 223: Reconstruct Loss: 1.0588, Valid Reconstruct Loss: 1.0007\n",
      "#Epoch 224: Reconstruct Loss: 1.0544, Valid Reconstruct Loss: 1.0003\n",
      "#Epoch 225: Reconstruct Loss: 1.1583, Valid Reconstruct Loss: 1.0001\n",
      "#Epoch 226: Reconstruct Loss: 1.0357, Valid Reconstruct Loss: 0.9999\n",
      "#Epoch 227: Reconstruct Loss: 1.1612, Valid Reconstruct Loss: 0.9998\n",
      "#Epoch 228: Reconstruct Loss: 1.0588, Valid Reconstruct Loss: 0.9997\n",
      "#Epoch 229: Reconstruct Loss: 1.0519, Valid Reconstruct Loss: 0.9998\n",
      "#Epoch 230: Reconstruct Loss: 1.0501, Valid Reconstruct Loss: 1.0000\n",
      "#Epoch 231: Reconstruct Loss: 1.0356, Valid Reconstruct Loss: 1.0000\n",
      "#Epoch 232: Reconstruct Loss: 1.0259, Valid Reconstruct Loss: 1.0002\n",
      "#Epoch 233: Reconstruct Loss: 1.0273, Valid Reconstruct Loss: 1.0005\n",
      "#Epoch 234: Reconstruct Loss: 1.0366, Valid Reconstruct Loss: 1.0009\n",
      "#Epoch 235: Reconstruct Loss: 1.0335, Valid Reconstruct Loss: 1.0009\n",
      "#Epoch 236: Reconstruct Loss: 1.1420, Valid Reconstruct Loss: 1.0008\n",
      "#Epoch 237: Reconstruct Loss: 1.0233, Valid Reconstruct Loss: 1.0007\n",
      "#Epoch 238: Reconstruct Loss: 1.0285, Valid Reconstruct Loss: 1.0007\n",
      "#Epoch 239: Reconstruct Loss: 1.0321, Valid Reconstruct Loss: 1.0009\n",
      "#Epoch 240: Reconstruct Loss: 1.0235, Valid Reconstruct Loss: 1.0011\n",
      "#Epoch 241: Reconstruct Loss: 1.0499, Valid Reconstruct Loss: 1.0012\n",
      "#Epoch 242: Reconstruct Loss: 1.1361, Valid Reconstruct Loss: 1.0014\n",
      "#Epoch 243: Reconstruct Loss: 1.1586, Valid Reconstruct Loss: 1.0014\n",
      "#Epoch 244: Reconstruct Loss: 1.0564, Valid Reconstruct Loss: 1.0011\n",
      "#Epoch 245: Reconstruct Loss: 1.1357, Valid Reconstruct Loss: 1.0005\n",
      "#Epoch 246: Reconstruct Loss: 1.0279, Valid Reconstruct Loss: 1.0002\n",
      "#Epoch 247: Reconstruct Loss: 1.0363, Valid Reconstruct Loss: 1.0005\n",
      "#Epoch 248: Reconstruct Loss: 1.1535, Valid Reconstruct Loss: 1.0004\n",
      "#Epoch 249: Reconstruct Loss: 1.0513, Valid Reconstruct Loss: 1.0005\n",
      "#Epoch 250: Reconstruct Loss: 1.0293, Valid Reconstruct Loss: 1.0004\n",
      "#Epoch 251: Reconstruct Loss: 1.0557, Valid Reconstruct Loss: 1.0000\n",
      "#Epoch 252: Reconstruct Loss: 1.0382, Valid Reconstruct Loss: 0.9998\n",
      "#Epoch 253: Reconstruct Loss: 1.0503, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 254: Reconstruct Loss: 1.0402, Valid Reconstruct Loss: 0.9992\n",
      "#Epoch 255: Reconstruct Loss: 1.0392, Valid Reconstruct Loss: 0.9990\n",
      "#Epoch 256: Reconstruct Loss: 1.1382, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 257: Reconstruct Loss: 1.1292, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 258: Reconstruct Loss: 1.0355, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 259: Reconstruct Loss: 1.0380, Valid Reconstruct Loss: 0.9992\n",
      "#Epoch 260: Reconstruct Loss: 1.1357, Valid Reconstruct Loss: 0.9992\n",
      "#Epoch 261: Reconstruct Loss: 1.0296, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 262: Reconstruct Loss: 1.1252, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 263: Reconstruct Loss: 1.0440, Valid Reconstruct Loss: 0.9994\n",
      "#Epoch 264: Reconstruct Loss: 1.0284, Valid Reconstruct Loss: 0.9992\n",
      "#Epoch 265: Reconstruct Loss: 1.0301, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 266: Reconstruct Loss: 1.0506, Valid Reconstruct Loss: 0.9998\n",
      "#Epoch 267: Reconstruct Loss: 1.0277, Valid Reconstruct Loss: 0.9998\n",
      "#Epoch 268: Reconstruct Loss: 1.0426, Valid Reconstruct Loss: 0.9994\n",
      "#Epoch 269: Reconstruct Loss: 1.0384, Valid Reconstruct Loss: 0.9993\n",
      "#Epoch 270: Reconstruct Loss: 1.0583, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 271: Reconstruct Loss: 1.0488, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 272: Reconstruct Loss: 1.0379, Valid Reconstruct Loss: 0.9990\n",
      "#Epoch 273: Reconstruct Loss: 1.0339, Valid Reconstruct Loss: 0.9988\n",
      "#Epoch 274: Reconstruct Loss: 1.1343, Valid Reconstruct Loss: 0.9989\n",
      "#Epoch 275: Reconstruct Loss: 1.0610, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 276: Reconstruct Loss: 1.0364, Valid Reconstruct Loss: 0.9990\n",
      "#Epoch 277: Reconstruct Loss: 1.0383, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 278: Reconstruct Loss: 1.1302, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 279: Reconstruct Loss: 1.0279, Valid Reconstruct Loss: 0.9993\n",
      "#Epoch 280: Reconstruct Loss: 1.0379, Valid Reconstruct Loss: 0.9992\n",
      "#Epoch 281: Reconstruct Loss: 1.0352, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 282: Reconstruct Loss: 1.1431, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 283: Reconstruct Loss: 1.0308, Valid Reconstruct Loss: 0.9995\n",
      "#Epoch 284: Reconstruct Loss: 1.1403, Valid Reconstruct Loss: 0.9994\n",
      "#Epoch 285: Reconstruct Loss: 1.0396, Valid Reconstruct Loss: 0.9991\n",
      "#Epoch 286: Reconstruct Loss: 1.0271, Valid Reconstruct Loss: 0.9989\n",
      "#Epoch 287: Reconstruct Loss: 1.0314, Valid Reconstruct Loss: 0.9988\n",
      "#Epoch 288: Reconstruct Loss: 1.0331, Valid Reconstruct Loss: 0.9989\n",
      "#Epoch 289: Reconstruct Loss: 1.0598, Valid Reconstruct Loss: 0.9987\n",
      "#Epoch 290: Reconstruct Loss: 1.0350, Valid Reconstruct Loss: 0.9988\n",
      "#Epoch 291: Reconstruct Loss: 1.0527, Valid Reconstruct Loss: 0.9985\n",
      "#Epoch 292: Reconstruct Loss: 1.0368, Valid Reconstruct Loss: 0.9981\n",
      "#Epoch 293: Reconstruct Loss: 1.0257, Valid Reconstruct Loss: 0.9978\n",
      "#Epoch 294: Reconstruct Loss: 1.1375, Valid Reconstruct Loss: 0.9970\n",
      "#Epoch 295: Reconstruct Loss: 1.0284, Valid Reconstruct Loss: 0.9964\n",
      "#Epoch 296: Reconstruct Loss: 1.0412, Valid Reconstruct Loss: 0.9961\n",
      "#Epoch 297: Reconstruct Loss: 1.0240, Valid Reconstruct Loss: 0.9959\n",
      "#Epoch 298: Reconstruct Loss: 1.0495, Valid Reconstruct Loss: 0.9923\n",
      "#Epoch 299: Reconstruct Loss: 1.0251, Valid Reconstruct Loss: 0.9880\n",
      "#Epoch 300: Reconstruct Loss: 1.0400, Valid Reconstruct Loss: 0.9853\n",
      "DenoisingAutoencoder(\n",
      "  in_features=2000, out_features=20, bias=True\n",
      "  (dropout): Dropout(p=0, inplace=False)\n",
      ")\n",
      "=====Denoising Autoencoding layer=======\n",
      "#Epoch 0: Valid Reconstruct Loss: 0.0703\n",
      "#Epoch   1: Reconstruct Loss: 0.0703, Valid Reconstruct Loss: 0.0701\n",
      "#Epoch   2: Reconstruct Loss: 0.0699, Valid Reconstruct Loss: 0.0692\n",
      "#Epoch   3: Reconstruct Loss: 0.0682, Valid Reconstruct Loss: 0.0643\n",
      "#Epoch   4: Reconstruct Loss: 0.0612, Valid Reconstruct Loss: 0.0421\n",
      "#Epoch   5: Reconstruct Loss: 0.0363, Valid Reconstruct Loss: 0.0101\n",
      "#Epoch   6: Reconstruct Loss: 0.0113, Valid Reconstruct Loss: 0.0190\n",
      "#Epoch   7: Reconstruct Loss: 0.0073, Valid Reconstruct Loss: 0.0022\n",
      "#Epoch   8: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch   9: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0022\n",
      "#Epoch  10: Reconstruct Loss: 0.0052, Valid Reconstruct Loss: 0.0085\n",
      "#Epoch  11: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0068\n",
      "#Epoch  12: Reconstruct Loss: 0.0068, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch  13: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0073\n",
      "#Epoch  14: Reconstruct Loss: 0.0089, Valid Reconstruct Loss: 0.0117\n",
      "#Epoch  15: Reconstruct Loss: 0.0052, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch  16: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0051\n",
      "#Epoch  17: Reconstruct Loss: 0.0040, Valid Reconstruct Loss: 0.0049\n",
      "#Epoch  18: Reconstruct Loss: 0.0067, Valid Reconstruct Loss: 0.0098\n",
      "#Epoch  19: Reconstruct Loss: 0.0049, Valid Reconstruct Loss: 0.0051\n",
      "#Epoch  20: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch  21: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0058\n",
      "#Epoch  22: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch  23: Reconstruct Loss: 0.0069, Valid Reconstruct Loss: 0.0089\n",
      "#Epoch  24: Reconstruct Loss: 0.0082, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch  25: Reconstruct Loss: 0.0065, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch  26: Reconstruct Loss: 0.0115, Valid Reconstruct Loss: 0.0084\n",
      "#Epoch  27: Reconstruct Loss: 0.0127, Valid Reconstruct Loss: 0.0057\n",
      "#Epoch  28: Reconstruct Loss: 0.0127, Valid Reconstruct Loss: 0.0146\n",
      "#Epoch  29: Reconstruct Loss: 0.0050, Valid Reconstruct Loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch  30: Reconstruct Loss: 0.0056, Valid Reconstruct Loss: 0.0075\n",
      "#Epoch  31: Reconstruct Loss: 0.0058, Valid Reconstruct Loss: 0.0081\n",
      "#Epoch  32: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0042\n",
      "#Epoch  33: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0058\n",
      "#Epoch  34: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch  35: Reconstruct Loss: 0.0050, Valid Reconstruct Loss: 0.0022\n",
      "#Epoch  36: Reconstruct Loss: 0.0043, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch  37: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0052\n",
      "#Epoch  38: Reconstruct Loss: 0.0047, Valid Reconstruct Loss: 0.0040\n",
      "#Epoch  39: Reconstruct Loss: 0.0053, Valid Reconstruct Loss: 0.0024\n",
      "#Epoch  40: Reconstruct Loss: 0.0050, Valid Reconstruct Loss: 0.0076\n",
      "#Epoch  41: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0055\n",
      "#Epoch  42: Reconstruct Loss: 0.0070, Valid Reconstruct Loss: 0.0065\n",
      "#Epoch  43: Reconstruct Loss: 0.0040, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch  44: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0058\n",
      "#Epoch  45: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0027\n",
      "#Epoch  46: Reconstruct Loss: 0.0048, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch  47: Reconstruct Loss: 0.0051, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch  48: Reconstruct Loss: 0.0082, Valid Reconstruct Loss: 0.0077\n",
      "#Epoch  49: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0046\n",
      "#Epoch  50: Reconstruct Loss: 0.0054, Valid Reconstruct Loss: 0.0066\n",
      "#Epoch  51: Reconstruct Loss: 0.0079, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch  52: Reconstruct Loss: 0.0064, Valid Reconstruct Loss: 0.0027\n",
      "#Epoch  53: Reconstruct Loss: 0.0117, Valid Reconstruct Loss: 0.0138\n",
      "#Epoch  54: Reconstruct Loss: 0.0053, Valid Reconstruct Loss: 0.0022\n",
      "#Epoch  55: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0024\n",
      "#Epoch  56: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0047\n",
      "#Epoch  57: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0059\n",
      "#Epoch  58: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0045\n",
      "#Epoch  59: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch  60: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0046\n",
      "#Epoch  61: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0043\n",
      "#Epoch  62: Reconstruct Loss: 0.0071, Valid Reconstruct Loss: 0.0120\n",
      "#Epoch  63: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch  64: Reconstruct Loss: 0.0043, Valid Reconstruct Loss: 0.0022\n",
      "#Epoch  65: Reconstruct Loss: 0.0075, Valid Reconstruct Loss: 0.0074\n",
      "#Epoch  66: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0052\n",
      "#Epoch  67: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0048\n",
      "#Epoch  68: Reconstruct Loss: 0.0054, Valid Reconstruct Loss: 0.0018\n",
      "#Epoch  69: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0043\n",
      "#Epoch  70: Reconstruct Loss: 0.0055, Valid Reconstruct Loss: 0.0019\n",
      "#Epoch  71: Reconstruct Loss: 0.0065, Valid Reconstruct Loss: 0.0037\n",
      "#Epoch  72: Reconstruct Loss: 0.0065, Valid Reconstruct Loss: 0.0026\n",
      "#Epoch  73: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch  74: Reconstruct Loss: 0.0045, Valid Reconstruct Loss: 0.0067\n",
      "#Epoch  75: Reconstruct Loss: 0.0056, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch  76: Reconstruct Loss: 0.0053, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch  77: Reconstruct Loss: 0.0045, Valid Reconstruct Loss: 0.0042\n",
      "#Epoch  78: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0097\n",
      "#Epoch  79: Reconstruct Loss: 0.0047, Valid Reconstruct Loss: 0.0107\n",
      "#Epoch  80: Reconstruct Loss: 0.0056, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch  81: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch  82: Reconstruct Loss: 0.0052, Valid Reconstruct Loss: 0.0106\n",
      "#Epoch  83: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch  84: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0019\n",
      "#Epoch  85: Reconstruct Loss: 0.0062, Valid Reconstruct Loss: 0.0071\n",
      "#Epoch  86: Reconstruct Loss: 0.0070, Valid Reconstruct Loss: 0.0105\n",
      "#Epoch  87: Reconstruct Loss: 0.0094, Valid Reconstruct Loss: 0.0139\n",
      "#Epoch  88: Reconstruct Loss: 0.0093, Valid Reconstruct Loss: 0.0019\n",
      "#Epoch  89: Reconstruct Loss: 0.0088, Valid Reconstruct Loss: 0.0053\n",
      "#Epoch  90: Reconstruct Loss: 0.0083, Valid Reconstruct Loss: 0.0017\n",
      "#Epoch  91: Reconstruct Loss: 0.0076, Valid Reconstruct Loss: 0.0024\n",
      "#Epoch  92: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0071\n",
      "#Epoch  93: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0041\n",
      "#Epoch  94: Reconstruct Loss: 0.0058, Valid Reconstruct Loss: 0.0018\n",
      "#Epoch  95: Reconstruct Loss: 0.0056, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch  96: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0060\n",
      "#Epoch  97: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch  98: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0015\n",
      "#Epoch  99: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0040\n",
      "#Epoch 100: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0014\n",
      "Switching to learning rate 0.005000\n",
      "#Epoch 101: Reconstruct Loss: 0.0095, Valid Reconstruct Loss: 0.0016\n",
      "#Epoch 102: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0017\n",
      "#Epoch 103: Reconstruct Loss: 0.0053, Valid Reconstruct Loss: 0.0020\n",
      "#Epoch 104: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0024\n",
      "#Epoch 105: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0027\n",
      "#Epoch 106: Reconstruct Loss: 0.0043, Valid Reconstruct Loss: 0.0030\n",
      "#Epoch 107: Reconstruct Loss: 0.0055, Valid Reconstruct Loss: 0.0036\n",
      "#Epoch 108: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0042\n",
      "#Epoch 109: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0043\n",
      "#Epoch 110: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch 111: Reconstruct Loss: 0.0061, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch 112: Reconstruct Loss: 0.0050, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch 113: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0041\n",
      "#Epoch 114: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0045\n",
      "#Epoch 115: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0036\n",
      "#Epoch 116: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 117: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0029\n",
      "#Epoch 118: Reconstruct Loss: 0.0065, Valid Reconstruct Loss: 0.0039\n",
      "#Epoch 119: Reconstruct Loss: 0.0062, Valid Reconstruct Loss: 0.0047\n",
      "#Epoch 120: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0039\n",
      "#Epoch 121: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0036\n",
      "#Epoch 122: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch 123: Reconstruct Loss: 0.0052, Valid Reconstruct Loss: 0.0037\n",
      "#Epoch 124: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 125: Reconstruct Loss: 0.0069, Valid Reconstruct Loss: 0.0037\n",
      "#Epoch 126: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0041\n",
      "#Epoch 127: Reconstruct Loss: 0.0056, Valid Reconstruct Loss: 0.0047\n",
      "#Epoch 128: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0049\n",
      "#Epoch 129: Reconstruct Loss: 0.0051, Valid Reconstruct Loss: 0.0053\n",
      "#Epoch 130: Reconstruct Loss: 0.0080, Valid Reconstruct Loss: 0.0063\n",
      "#Epoch 131: Reconstruct Loss: 0.0047, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch 132: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch 133: Reconstruct Loss: 0.0115, Valid Reconstruct Loss: 0.0045\n",
      "#Epoch 134: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0053\n",
      "#Epoch 135: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0053\n",
      "#Epoch 136: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0044\n",
      "#Epoch 137: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0040\n",
      "#Epoch 138: Reconstruct Loss: 0.0053, Valid Reconstruct Loss: 0.0036\n",
      "#Epoch 139: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0041\n",
      "#Epoch 140: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0041\n",
      "#Epoch 141: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0043\n",
      "#Epoch 142: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0046\n",
      "#Epoch 143: Reconstruct Loss: 0.0045, Valid Reconstruct Loss: 0.0042\n",
      "#Epoch 144: Reconstruct Loss: 0.0048, Valid Reconstruct Loss: 0.0040\n",
      "#Epoch 145: Reconstruct Loss: 0.0043, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 146: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 147: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0039\n",
      "#Epoch 148: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 149: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0039\n",
      "#Epoch 150: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0040\n",
      "#Epoch 151: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch 152: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch 153: Reconstruct Loss: 0.0049, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 154: Reconstruct Loss: 0.0056, Valid Reconstruct Loss: 0.0039\n",
      "#Epoch 155: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0039\n",
      "#Epoch 156: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 157: Reconstruct Loss: 0.0059, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 158: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0036\n",
      "#Epoch 159: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch 160: Reconstruct Loss: 0.0028, Valid Reconstruct Loss: 0.0036\n",
      "#Epoch 161: Reconstruct Loss: 0.0030, Valid Reconstruct Loss: 0.0036\n",
      "#Epoch 162: Reconstruct Loss: 0.0050, Valid Reconstruct Loss: 0.0030\n",
      "#Epoch 163: Reconstruct Loss: 0.0063, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 164: Reconstruct Loss: 0.0027, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch 165: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 166: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0037\n",
      "#Epoch 167: Reconstruct Loss: 0.0028, Valid Reconstruct Loss: 0.0040\n",
      "#Epoch 168: Reconstruct Loss: 0.0029, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch 169: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0041\n",
      "#Epoch 170: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0046\n",
      "#Epoch 171: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0043\n",
      "#Epoch 172: Reconstruct Loss: 0.0040, Valid Reconstruct Loss: 0.0037\n",
      "#Epoch 173: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0030\n",
      "#Epoch 174: Reconstruct Loss: 0.0030, Valid Reconstruct Loss: 0.0030\n",
      "#Epoch 175: Reconstruct Loss: 0.0028, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 176: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0027\n",
      "#Epoch 177: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0029\n",
      "#Epoch 178: Reconstruct Loss: 0.0049, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 179: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 180: Reconstruct Loss: 0.0043, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch 181: Reconstruct Loss: 0.0043, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 182: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch 183: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0037\n",
      "#Epoch 184: Reconstruct Loss: 0.0050, Valid Reconstruct Loss: 0.0043\n",
      "#Epoch 185: Reconstruct Loss: 0.0058, Valid Reconstruct Loss: 0.0046\n",
      "#Epoch 186: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0053\n",
      "#Epoch 187: Reconstruct Loss: 0.0027, Valid Reconstruct Loss: 0.0052\n",
      "#Epoch 188: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0050\n",
      "#Epoch 189: Reconstruct Loss: 0.0027, Valid Reconstruct Loss: 0.0049\n",
      "#Epoch 190: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0046\n",
      "#Epoch 191: Reconstruct Loss: 0.0059, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch 192: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0030\n",
      "#Epoch 193: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 194: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0028\n",
      "#Epoch 195: Reconstruct Loss: 0.0051, Valid Reconstruct Loss: 0.0025\n",
      "#Epoch 196: Reconstruct Loss: 0.0051, Valid Reconstruct Loss: 0.0030\n",
      "#Epoch 197: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 198: Reconstruct Loss: 0.0047, Valid Reconstruct Loss: 0.0038\n",
      "#Epoch 199: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 200: Reconstruct Loss: 0.0029, Valid Reconstruct Loss: 0.0033\n",
      "Switching to learning rate 0.000500\n",
      "#Epoch 201: Reconstruct Loss: 0.0038, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 202: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 203: Reconstruct Loss: 0.0048, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 204: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 205: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 206: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 207: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 208: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 209: Reconstruct Loss: 0.0073, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 210: Reconstruct Loss: 0.0026, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 211: Reconstruct Loss: 0.0043, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 212: Reconstruct Loss: 0.0052, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 213: Reconstruct Loss: 0.0051, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 214: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 215: Reconstruct Loss: 0.0055, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 216: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 217: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 218: Reconstruct Loss: 0.0040, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 219: Reconstruct Loss: 0.0176, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 220: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 221: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 222: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 223: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 224: Reconstruct Loss: 0.0027, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 225: Reconstruct Loss: 0.0030, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 226: Reconstruct Loss: 0.0028, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 227: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 228: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 229: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 230: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 231: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 232: Reconstruct Loss: 0.0055, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 233: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 234: Reconstruct Loss: 0.0051, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 235: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 236: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 237: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 238: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 239: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 240: Reconstruct Loss: 0.0047, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 241: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 242: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 243: Reconstruct Loss: 0.0030, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 244: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 245: Reconstruct Loss: 0.0048, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 246: Reconstruct Loss: 0.0033, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 247: Reconstruct Loss: 0.0070, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 248: Reconstruct Loss: 0.0046, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 249: Reconstruct Loss: 0.0048, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 250: Reconstruct Loss: 0.0052, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 251: Reconstruct Loss: 0.0049, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 252: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 253: Reconstruct Loss: 0.0026, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 254: Reconstruct Loss: 0.0039, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 255: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 256: Reconstruct Loss: 0.0029, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 257: Reconstruct Loss: 0.0029, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 258: Reconstruct Loss: 0.0042, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 259: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0031\n",
      "#Epoch 260: Reconstruct Loss: 0.0096, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 261: Reconstruct Loss: 0.0097, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 262: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 263: Reconstruct Loss: 0.0103, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 264: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 265: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 266: Reconstruct Loss: 0.0030, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 267: Reconstruct Loss: 0.0095, Valid Reconstruct Loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 268: Reconstruct Loss: 0.0061, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 269: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 270: Reconstruct Loss: 0.0050, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 271: Reconstruct Loss: 0.0045, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 272: Reconstruct Loss: 0.0029, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 273: Reconstruct Loss: 0.0047, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 274: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 275: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 276: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 277: Reconstruct Loss: 0.0040, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 278: Reconstruct Loss: 0.0027, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 279: Reconstruct Loss: 0.0036, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 280: Reconstruct Loss: 0.0056, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 281: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0032\n",
      "#Epoch 282: Reconstruct Loss: 0.0061, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 283: Reconstruct Loss: 0.0054, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 284: Reconstruct Loss: 0.0031, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 285: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 286: Reconstruct Loss: 0.0040, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 287: Reconstruct Loss: 0.0060, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 288: Reconstruct Loss: 0.0035, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 289: Reconstruct Loss: 0.0032, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 290: Reconstruct Loss: 0.0100, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch 291: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch 292: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0035\n",
      "#Epoch 293: Reconstruct Loss: 0.0034, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 294: Reconstruct Loss: 0.0026, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 295: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 296: Reconstruct Loss: 0.0037, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 297: Reconstruct Loss: 0.0030, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 298: Reconstruct Loss: 0.0041, Valid Reconstruct Loss: 0.0033\n",
      "#Epoch 299: Reconstruct Loss: 0.0027, Valid Reconstruct Loss: 0.0034\n",
      "#Epoch 300: Reconstruct Loss: 0.0044, Valid Reconstruct Loss: 0.0033\n",
      "=====Stacked Denoising Autoencoding Layer=======\n",
      "#Epoch 0: Valid Reconstruct Loss: 5409.6025\n",
      "#Epoch   1: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   2: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   3: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   4: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   5: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   6: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   7: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   8: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch   9: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  10: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  11: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  12: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  13: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  14: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  15: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  16: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  17: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  18: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  19: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  20: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  21: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  22: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  23: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  24: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  25: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  26: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n",
      "#Epoch  27: Reconstruct Loss: nan, Valid Reconstruct Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fz/ydn1fhs96ynfsjb34pg0qrwc0000gn/T/ipykernel_42174/3496139377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Train the stacked denoising autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0msdae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrupt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Save the weights as pre-trained model for IDEC/DEC/DCC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fz/ydn1fhs96ynfsjb34pg0qrwc0000gn/T/ipykernel_42174/1319558965.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, trainloader, validloader, lr, num_epochs, corrupt, loss_type)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0minputs_corr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_corr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_corr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mrecon_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fz/ydn1fhs96ynfsjb34pg0qrwc0000gn/T/ipykernel_42174/1319558965.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enc_mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch.utils.data\n",
    "import argparse\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data for pre-training\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        Netflix('', train=True),\n",
    "        batch_size=256, shuffle=True, num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        Netflix('', train=False),\n",
    "        batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "    sdae = StackedDAE(input_dim=17770, z_dim=20, binary=False,\n",
    "                      encodeLayer=[500, 500, 2000], decodeLayer=[2000, 500, 500], activation=\"relu\",\n",
    "                      dropout=0)\n",
    "    \n",
    "    # Print the pre-train model structure\n",
    "    print(sdae)\n",
    "    sdae.pretrain(train_loader, test_loader, lr=0.05, batch_size=256, #alpha, batch, epochs\n",
    "                  num_epochs=300, corrupt=0.2, loss_type=\"mse\")\n",
    "    \n",
    "    # Train the stacked denoising autoencoder\n",
    "    sdae.fit(train_loader, test_loader, lr=0.1, num_epochs=500, corrupt=0.2, loss_type=\"mse\")\n",
    "    \n",
    "    # Save the weights as pre-trained model for IDEC/DEC/DCC\n",
    "    sdae.save_model(r\"/Users/niharika/Documents/Niharika/Third Quarter/ECS 271 ML/Assignment2/sdae_netflix_weights1.pt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "SDAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
